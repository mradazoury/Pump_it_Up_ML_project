{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Packages & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit, validation_curve, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler, LabelEncoder, scale, MinMaxScaler, PolynomialFeatures, Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from xgboost import plot_importance\n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "import scipy.stats as stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import math as m\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Datasets\n",
    "train_data = pd.read_csv(\"training_set_values.csv\")\n",
    "train_labels = pd.read_csv(\"training_set_labels.csv\")\n",
    "test_data = pd.read_csv(\"test_set_values.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# script for returning elevation from lat, long, based on open elevation data\n",
    "# which in turn is based on SRTM\n",
    "def get_elevation(lat, long):\n",
    "    query = ('https://api.open-elevation.com/api/v1/lookup'\n",
    "             f'?locations={lat},{long}')\n",
    "    r = requests.get(query).json()  # json object, various ways you can extract value\n",
    "    # one approach is to use pandas json functionality:\n",
    "    elevation = pd.io.json.json_normalize(r, 'results')['elevation'].values[0].astype(int)\n",
    "    return elevation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = train_data.latitude[0]\n",
    "long = train_data.longitude[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get_elevation(lat,long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join Labels with Train data\n",
    "train_labels = train_labels.drop(columns='id')\n",
    "train_data = train_data.join(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
       "1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
       "3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
       "4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private       ...        \\\n",
       "0  34.938093  -9.856322                  none            0       ...         \n",
       "1  34.698766  -2.147466              Zahanati            0       ...         \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0       ...         \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0       ...         \n",
       "4  31.130847  -1.825359               Shuleni            0       ...         \n",
       "\n",
       "  water_quality quality_group      quantity  quantity_group  \\\n",
       "0          soft          good        enough          enough   \n",
       "1          soft          good  insufficient    insufficient   \n",
       "2          soft          good        enough          enough   \n",
       "3          soft          good           dry             dry   \n",
       "4          soft          good      seasonal        seasonal   \n",
       "\n",
       "                 source           source_type source_class  \\\n",
       "0                spring                spring  groundwater   \n",
       "1  rainwater harvesting  rainwater harvesting      surface   \n",
       "2                   dam                   dam      surface   \n",
       "3           machine dbh              borehole  groundwater   \n",
       "4  rainwater harvesting  rainwater harvesting      surface   \n",
       "\n",
       "               waterpoint_type waterpoint_type_group    status_group  \n",
       "0           communal standpipe    communal standpipe      functional  \n",
       "1           communal standpipe    communal standpipe      functional  \n",
       "2  communal standpipe multiple    communal standpipe      functional  \n",
       "3  communal standpipe multiple    communal standpipe  non functional  \n",
       "4           communal standpipe    communal standpipe      functional  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Dmdd</td>\n",
       "      <td>1996</td>\n",
       "      <td>DMDD</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>Dinamu Secondary School</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>1569</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>Kimnyak</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>Puma Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>Finn Water</td>\n",
       "      <td>267</td>\n",
       "      <td>FINN WATER</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>Kwa Mzee Pange</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>Bruder</td>\n",
       "      <td>1260</td>\n",
       "      <td>BRUDER</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>Kwa Mzee Turuka</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "0  50785         0.0    2013-02-04                    Dmdd        1996   \n",
       "1  51630         0.0    2013-02-04  Government Of Tanzania        1569   \n",
       "2  17168         0.0    2013-02-01                     NaN        1567   \n",
       "3  45559         0.0    2013-01-22              Finn Water         267   \n",
       "4  49871       500.0    2013-03-27                  Bruder        1260   \n",
       "\n",
       "    installer  longitude   latitude                 wpt_name  num_private  \\\n",
       "0        DMDD  35.290799  -4.059696  Dinamu Secondary School            0   \n",
       "1         DWE  36.656709  -3.309214                  Kimnyak            0   \n",
       "2         NaN  34.767863  -5.004344           Puma Secondary            0   \n",
       "3  FINN WATER  38.058046  -9.418672           Kwa Mzee Pange            0   \n",
       "4      BRUDER  35.006123 -10.950412          Kwa Mzee Turuka            0   \n",
       "\n",
       "           ...          payment_type water_quality quality_group  \\\n",
       "0          ...             never pay          soft          good   \n",
       "1          ...             never pay          soft          good   \n",
       "2          ...             never pay          soft          good   \n",
       "3          ...               unknown          soft          good   \n",
       "4          ...               monthly          soft          good   \n",
       "\n",
       "       quantity  quantity_group                source           source_type  \\\n",
       "0      seasonal        seasonal  rainwater harvesting  rainwater harvesting   \n",
       "1  insufficient    insufficient                spring                spring   \n",
       "2  insufficient    insufficient  rainwater harvesting  rainwater harvesting   \n",
       "3           dry             dry          shallow well          shallow well   \n",
       "4        enough          enough                spring                spring   \n",
       "\n",
       "   source_class     waterpoint_type waterpoint_type_group  \n",
       "0       surface               other                 other  \n",
       "1   groundwater  communal standpipe    communal standpipe  \n",
       "2       surface               other                 other  \n",
       "3   groundwater               other                 other  \n",
       "4   groundwater  communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      "id                       59400 non-null int64\n",
      "amount_tsh               59400 non-null float64\n",
      "date_recorded            59400 non-null object\n",
      "funder                   55765 non-null object\n",
      "gps_height               59400 non-null int64\n",
      "installer                55745 non-null object\n",
      "longitude                59400 non-null float64\n",
      "latitude                 59400 non-null float64\n",
      "wpt_name                 59400 non-null object\n",
      "num_private              59400 non-null int64\n",
      "basin                    59400 non-null object\n",
      "subvillage               59029 non-null object\n",
      "region                   59400 non-null object\n",
      "region_code              59400 non-null int64\n",
      "district_code            59400 non-null int64\n",
      "lga                      59400 non-null object\n",
      "ward                     59400 non-null object\n",
      "population               59400 non-null int64\n",
      "public_meeting           56066 non-null object\n",
      "recorded_by              59400 non-null object\n",
      "scheme_management        55523 non-null object\n",
      "scheme_name              31234 non-null object\n",
      "permit                   56344 non-null object\n",
      "construction_year        59400 non-null int64\n",
      "extraction_type          59400 non-null object\n",
      "extraction_type_group    59400 non-null object\n",
      "extraction_type_class    59400 non-null object\n",
      "management               59400 non-null object\n",
      "management_group         59400 non-null object\n",
      "payment                  59400 non-null object\n",
      "payment_type             59400 non-null object\n",
      "water_quality            59400 non-null object\n",
      "quality_group            59400 non-null object\n",
      "quantity                 59400 non-null object\n",
      "quantity_group           59400 non-null object\n",
      "source                   59400 non-null object\n",
      "source_type              59400 non-null object\n",
      "source_class             59400 non-null object\n",
      "waterpoint_type          59400 non-null object\n",
      "waterpoint_type_group    59400 non-null object\n",
      "status_group             59400 non-null object\n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14850 entries, 0 to 14849\n",
      "Data columns (total 40 columns):\n",
      "id                       14850 non-null int64\n",
      "amount_tsh               14850 non-null float64\n",
      "date_recorded            14850 non-null object\n",
      "funder                   13981 non-null object\n",
      "gps_height               14850 non-null int64\n",
      "installer                13973 non-null object\n",
      "longitude                14850 non-null float64\n",
      "latitude                 14850 non-null float64\n",
      "wpt_name                 14850 non-null object\n",
      "num_private              14850 non-null int64\n",
      "basin                    14850 non-null object\n",
      "subvillage               14751 non-null object\n",
      "region                   14850 non-null object\n",
      "region_code              14850 non-null int64\n",
      "district_code            14850 non-null int64\n",
      "lga                      14850 non-null object\n",
      "ward                     14850 non-null object\n",
      "population               14850 non-null int64\n",
      "public_meeting           14029 non-null object\n",
      "recorded_by              14850 non-null object\n",
      "scheme_management        13881 non-null object\n",
      "scheme_name              7758 non-null object\n",
      "permit                   14113 non-null object\n",
      "construction_year        14850 non-null int64\n",
      "extraction_type          14850 non-null object\n",
      "extraction_type_group    14850 non-null object\n",
      "extraction_type_class    14850 non-null object\n",
      "management               14850 non-null object\n",
      "management_group         14850 non-null object\n",
      "payment                  14850 non-null object\n",
      "payment_type             14850 non-null object\n",
      "water_quality            14850 non-null object\n",
      "quality_group            14850 non-null object\n",
      "quantity                 14850 non-null object\n",
      "quantity_group           14850 non-null object\n",
      "source                   14850 non-null object\n",
      "source_type              14850 non-null object\n",
      "source_class             14850 non-null object\n",
      "waterpoint_type          14850 non-null object\n",
      "waterpoint_type_group    14850 non-null object\n",
      "dtypes: float64(3), int64(7), object(30)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop id and recorded from train dataset \n",
    "train_data= train_data.drop(columns=['id'])\n",
    "train_data= train_data.drop(columns=['recorded_by'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop id and recorded from test dataset \n",
    "test_id= test_data['id']\n",
    "test_data= test_data.drop(columns=['id'])\n",
    "test_data= test_data.drop(columns=['recorded_by'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Proposals\n",
    "Keeping all transformations in the same cell in an effort to make easy to recreate all steps for the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 39 columns):\n",
      "amount_tsh               59400 non-null float64\n",
      "date_recorded            59400 non-null object\n",
      "funder                   55765 non-null object\n",
      "gps_height               59400 non-null int64\n",
      "installer                55745 non-null object\n",
      "longitude                59400 non-null float64\n",
      "latitude                 59400 non-null float64\n",
      "wpt_name                 59400 non-null object\n",
      "num_private              59400 non-null int64\n",
      "basin                    59400 non-null object\n",
      "subvillage               59029 non-null object\n",
      "region                   59400 non-null object\n",
      "region_code              59400 non-null int64\n",
      "district_code            59400 non-null int64\n",
      "lga                      59400 non-null object\n",
      "ward                     59400 non-null object\n",
      "population               59400 non-null int64\n",
      "public_meeting           56066 non-null object\n",
      "scheme_management        55523 non-null object\n",
      "scheme_name              31234 non-null object\n",
      "permit                   56344 non-null object\n",
      "construction_year        59400 non-null int64\n",
      "extraction_type          59400 non-null object\n",
      "extraction_type_group    59400 non-null object\n",
      "extraction_type_class    59400 non-null object\n",
      "management               59400 non-null object\n",
      "management_group         59400 non-null object\n",
      "payment                  59400 non-null object\n",
      "payment_type             59400 non-null object\n",
      "water_quality            59400 non-null object\n",
      "quality_group            59400 non-null object\n",
      "quantity                 59400 non-null object\n",
      "quantity_group           59400 non-null object\n",
      "source                   59400 non-null object\n",
      "source_type              59400 non-null object\n",
      "source_class             59400 non-null object\n",
      "waterpoint_type          59400 non-null object\n",
      "waterpoint_type_group    59400 non-null object\n",
      "status_group             59400 non-null object\n",
      "dtypes: float64(3), int64(6), object(30)\n",
      "memory usage: 17.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0       0.700993\n",
      "500.0     0.052222\n",
      "50.0      0.041616\n",
      "1000.0    0.025051\n",
      "20.0      0.024630\n",
      "Name: amount_tsh, dtype: float64\n",
      "2011-03-15    0.009630\n",
      "2011-03-17    0.009394\n",
      "2013-02-03    0.009192\n",
      "2011-03-14    0.008754\n",
      "2011-03-16    0.008636\n",
      "Name: date_recorded, dtype: float64\n",
      "Government Of Tanzania    0.152929\n",
      "Danida                    0.052424\n",
      "Hesawa                    0.037071\n",
      "Rwssp                     0.023131\n",
      "World Bank                0.022710\n",
      "Name: funder, dtype: float64\n",
      " 0     0.344074\n",
      "-15    0.001010\n",
      "-16    0.000926\n",
      "-13    0.000926\n",
      "-20    0.000875\n",
      "Name: gps_height, dtype: float64\n",
      "DWE           0.292963\n",
      "Government    0.030724\n",
      "RWE           0.020303\n",
      "Commu         0.017845\n",
      "DANIDA        0.017677\n",
      "Name: installer, dtype: float64\n",
      "0.000000     0.030505\n",
      "37.540901    0.000034\n",
      "33.010510    0.000034\n",
      "39.093484    0.000034\n",
      "32.972719    0.000034\n",
      "Name: longitude, dtype: float64\n",
      "-2.000000e-08    0.030505\n",
      "-6.985842e+00    0.000034\n",
      "-3.797579e+00    0.000034\n",
      "-6.981884e+00    0.000034\n",
      "-7.104625e+00    0.000034\n",
      "Name: latitude, dtype: float64\n",
      "none         0.059983\n",
      "Shuleni      0.029428\n",
      "Zahanati     0.013973\n",
      "Msikitini    0.009007\n",
      "Kanisani     0.005438\n",
      "Name: wpt_name, dtype: float64\n",
      "0    0.987256\n",
      "6    0.001364\n",
      "1    0.001229\n",
      "5    0.000774\n",
      "8    0.000774\n",
      "Name: num_private, dtype: float64\n",
      "Lake Victoria      0.172525\n",
      "Pangani            0.150505\n",
      "Rufiji             0.134276\n",
      "Internal           0.131061\n",
      "Lake Tanganyika    0.108283\n",
      "Name: basin, dtype: float64\n",
      "Madukani    0.008552\n",
      "Shuleni     0.008519\n",
      "Majengo     0.008451\n",
      "Kati        0.006279\n",
      "Mtakuja     0.004411\n",
      "Name: subvillage, dtype: float64\n",
      "Iringa         0.089125\n",
      "Shinyanga      0.083872\n",
      "Mbeya          0.078098\n",
      "Kilimanjaro    0.073721\n",
      "Morogoro       0.067441\n",
      "Name: region, dtype: float64\n",
      "11    0.089226\n",
      "17    0.084360\n",
      "12    0.078098\n",
      "3     0.073721\n",
      "5     0.068013\n",
      "Name: region_code, dtype: float64\n",
      "1    0.205438\n",
      "2    0.188098\n",
      "3    0.168316\n",
      "4    0.151498\n",
      "5    0.073333\n",
      "Name: district_code, dtype: float64\n",
      "Njombe          0.042138\n",
      "Arusha Rural    0.021077\n",
      "Moshi Rural     0.021061\n",
      "Bariadi         0.019815\n",
      "Rungwe          0.018620\n",
      "Name: lga, dtype: float64\n",
      "Igosi        0.005168\n",
      "Imalinyi     0.004242\n",
      "Siha Kati    0.003906\n",
      "Mdandu       0.003889\n",
      "Nduruma      0.003653\n",
      "Name: ward, dtype: float64\n",
      "0      0.359949\n",
      "1      0.118266\n",
      "200    0.032660\n",
      "150    0.031852\n",
      "250    0.028300\n",
      "Name: population, dtype: float64\n",
      "True     0.858771\n",
      "False    0.085101\n",
      "Name: public_meeting, dtype: float64\n",
      "VWC                0.619411\n",
      "WUG                0.087643\n",
      "Water authority    0.053081\n",
      "WUA                0.048535\n",
      "Water Board        0.046263\n",
      "Name: scheme_management, dtype: float64\n",
      "K                0.011481\n",
      "None             0.010842\n",
      "Borehole         0.009192\n",
      "Chalinze wate    0.006818\n",
      "M                0.006734\n",
      "Name: scheme_name, dtype: float64\n",
      "True     0.654074\n",
      "False    0.294478\n",
      "Name: permit, dtype: float64\n",
      "0       0.348636\n",
      "2010    0.044529\n",
      "2008    0.043990\n",
      "2009    0.042643\n",
      "2000    0.035202\n",
      "Name: construction_year, dtype: float64\n",
      "gravity        0.450842\n",
      "nira/tanira    0.137273\n",
      "other          0.108249\n",
      "submersible    0.080202\n",
      "swn 80         0.061785\n",
      "Name: extraction_type, dtype: float64\n",
      "gravity        0.450842\n",
      "nira/tanira    0.137273\n",
      "other          0.108249\n",
      "submersible    0.104024\n",
      "swn 80         0.061785\n",
      "Name: extraction_type_group, dtype: float64\n",
      "gravity        0.450842\n",
      "handpump       0.277037\n",
      "other          0.108249\n",
      "submersible    0.104024\n",
      "motorpump      0.050286\n",
      "Name: extraction_type_class, dtype: float64\n",
      "vwc                 0.681936\n",
      "wug                 0.109680\n",
      "water board         0.049377\n",
      "wua                 0.042677\n",
      "private operator    0.033182\n",
      "Name: management, dtype: float64\n",
      "user-group    0.883670\n",
      "commercial    0.061246\n",
      "parastatal    0.029764\n",
      "other         0.015875\n",
      "unknown       0.009444\n",
      "Name: management_group, dtype: float64\n",
      "never pay                0.426734\n",
      "pay per bucket           0.151263\n",
      "pay monthly              0.139731\n",
      "unknown                  0.137323\n",
      "pay when scheme fails    0.065892\n",
      "Name: payment, dtype: float64\n",
      "never pay     0.426734\n",
      "per bucket    0.151263\n",
      "monthly       0.139731\n",
      "unknown       0.137323\n",
      "on failure    0.065892\n",
      "Name: payment_type, dtype: float64\n",
      "soft        0.855522\n",
      "salty       0.081751\n",
      "unknown     0.031582\n",
      "milky       0.013535\n",
      "coloured    0.008249\n",
      "Name: water_quality, dtype: float64\n",
      "good       0.855522\n",
      "salty      0.087458\n",
      "unknown    0.031582\n",
      "milky      0.013535\n",
      "colored    0.008249\n",
      "Name: quality_group, dtype: float64\n",
      "enough          0.558687\n",
      "insufficient    0.254697\n",
      "dry             0.105152\n",
      "seasonal        0.068182\n",
      "unknown         0.013283\n",
      "Name: quantity, dtype: float64\n",
      "enough          0.558687\n",
      "insufficient    0.254697\n",
      "dry             0.105152\n",
      "seasonal        0.068182\n",
      "unknown         0.013283\n",
      "Name: quantity_group, dtype: float64\n",
      "spring                  0.286549\n",
      "shallow well            0.283232\n",
      "machine dbh             0.186448\n",
      "river                   0.161818\n",
      "rainwater harvesting    0.038636\n",
      "Name: source, dtype: float64\n",
      "spring                  0.286549\n",
      "shallow well            0.283232\n",
      "borehole                0.201162\n",
      "river/lake              0.174697\n",
      "rainwater harvesting    0.038636\n",
      "Name: source_type, dtype: float64\n",
      "groundwater    0.770943\n",
      "surface        0.224377\n",
      "unknown        0.004680\n",
      "Name: source_class, dtype: float64\n",
      "communal standpipe             0.480168\n",
      "hand pump                      0.294411\n",
      "other                          0.107407\n",
      "communal standpipe multiple    0.102744\n",
      "improved spring                0.013199\n",
      "Name: waterpoint_type, dtype: float64\n",
      "communal standpipe    0.582912\n",
      "hand pump             0.294411\n",
      "other                 0.107407\n",
      "improved spring       0.013199\n",
      "cattle trough         0.001953\n",
      "Name: waterpoint_type_group, dtype: float64\n",
      "functional                 0.543081\n",
      "non functional             0.384242\n",
      "functional needs repair    0.072677\n",
      "Name: status_group, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in train_data.columns:\n",
    "    inspect = train_data[i].value_counts()/len(train_data)\n",
    "    print(inspect.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute amount TSH of regions 'Dodoma','Kagera','Mbeya','Tabora' with the mean of the whole pop\n",
    "def amount_tsh_impute_regions(dataset):\n",
    "    for i in range(0, len(dataset)):\n",
    "        if dataset.amount_tsh[i] == 0:\n",
    "            if dataset.region[i] in ['Dodoma','Kagera','Mbeya','Tabora']:\n",
    "                dataset.amount_tsh[i] = dataset.amount_tsh.mean()\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = amount_tsh_impute_regions(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = amount_tsh_impute_regions(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coordinate_subv(dataset):\n",
    "#     coordinate_subv = dataset.groupby('subvillage').mean()[['latitude','longitude']]\n",
    "#     return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Impute latitude by the mean of the region\n",
    "# def impute_latitude(dataset):\n",
    "#     dataset['latitude'] = dataset['latitude'].replace({-0.00000002:np.nan})\n",
    "#     coordinate_subv = dataset.groupby('subvillage').mean()[['latitude','longitude']]\n",
    "#     coordinate_ward = dataset.groupby('ward').mean()[['latitude','longitude']]\n",
    "#     coordinate_lga = dataset.groupby('lga').mean()[['latitude','longitude']]\n",
    "#     coordinate_region = dataset.groupby('region').mean()[['latitude','longitude']]\n",
    "#     lat = dataset['latitude']\n",
    "#     if np.isnan(lat):\n",
    "#         imp_latitude = coordinate_subv.loc[dataset['subvillage'],'latitude']\n",
    "#         if np.isnan(imp_latitude):\n",
    "#             imp_latitude = coordinate_ward.loc[dataset['ward'],'latitude']\n",
    "#         if np.isnan(imp_latitude):\n",
    "#             imp_latitude = coordinate_lga.loc[dataset['lga'],'latitude']\n",
    "#         if np.isnan(imp_latitude):\n",
    "#             imp_latitude = coordinate_region.loc[dataset['region'],'latitude']\n",
    "#         return imp_latitude\n",
    "#     return latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['latitude'] = train_data.apply(impute_latitude, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Impute latitude by the mean of the region\n",
    "# def fix_latitude(dataset):\n",
    "#     for i in range(0, len(dataset)):\n",
    "#         if dataset.latitude[i] == -0.00000002:\n",
    "#             dataset.latitude[i] = dataset.latitude[dataset['region']==dataset.region[i]].mean()\n",
    "#     return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = fix_latitude(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = fix_latitude(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for Nan and ipute with the mean of the lowest level regional variable \n",
    "def impute_lat(dataset):\n",
    "    dataset['latitude'] = dataset['latitude'].replace({-0.00000002:np.nan})\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    for i in range(0, len(dataset)): \n",
    "        if m.isnan(dataset.latitude[i]) == True:\n",
    "            for j in (\"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\"):\n",
    "                if m.isnan(dataset.latitude[dataset[j] == dataset[j].iloc[i]].mean()) == False:\n",
    "                    dataset.latitude.iloc[i] = dataset.latitude[dataset[j] == dataset[j].iloc[i]].mean()\n",
    "                    break\n",
    "                elif j == \"basin\":\n",
    "                    dataset.latitude.iloc[i] = train_data['latitude'].mean()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = impute_lat(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = impute_lat(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Impute longitude by the mean of the region\n",
    "# def fix_longitude(dataset):\n",
    "#     for i in range(0, len(dataset)):\n",
    "#         if dataset.longitude[i] == 0:\n",
    "#             dataset.longitude[i] = dataset.longitude[dataset['region']==dataset.region[i]].mean()\n",
    "#     return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = fix_longitude(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = fix_longitude(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for Nan and ipute with the mean of the lowest level regional variable \n",
    "def impute_long(dataset):\n",
    "    dataset['longitude'] = dataset['longitude'].replace({0:np.nan})\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    for i in range(0, len(dataset)): \n",
    "        if m.isnan(dataset.longitude[i]) == True:\n",
    "            for j in (\"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\"):\n",
    "                if m.isnan(dataset.longitude[dataset[j] == dataset[j].iloc[i]].mean()) == False:\n",
    "                    dataset.longitude.iloc[i] = dataset.longitude[dataset[j] == dataset[j].iloc[i]].mean()\n",
    "                    break\n",
    "                elif j == \"basin\":\n",
    "                    dataset.longitude.iloc[i] = train_data['longitude'].mean()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = impute_long(train_data)\n",
    "test_data = impute_long(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data.columns:\n",
    "    inspect = train_data[i].value_counts()/len(train_data)\n",
    "    print(inspect.head(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for Nan and ipute with the mean of the lowest level regional variable \n",
    "def impute_pop(dataset):\n",
    "    dataset['population'] = dataset['population'].replace({0:np.nan})\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    for i in range(0, len(dataset)): \n",
    "        if m.isnan(dataset.population[i]) == True:\n",
    "            for j in (\"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\"):\n",
    "                if m.isnan(dataset.population[dataset[j] == dataset[j].iloc[i]].mean()) == False:\n",
    "                    dataset.population.iloc[i] = dataset.population[dataset[j] == dataset[j].iloc[i]].mean()\n",
    "                    break\n",
    "                elif j == \"basin\":\n",
    "                    dataset.population.iloc[i] = train_data['population'].mean()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = impute_pop(train_data)\n",
    "test_data = impute_pop(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(dataset):\n",
    "    tanz_pop = pd.read_csv(\"Tanzania_pop.csv\", delimiter=';')\n",
    "    dataset.insert(40,'region_pop', dataset['region'].map(tanz_pop.set_index('Region')['population']))\n",
    "    dataset['density'] = dataset['population'] / dataset['region_pop']\n",
    "    del dataset['region_pop']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = density(train_data)\n",
    "test_data = density(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fields that require intensive review are: installer, funder, scheme_name, ward, lga, wpt_name, subvillage\n",
    "grouping_col = train_data[['basin',\n",
    "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward','extraction_type',\n",
    "       'extraction_type_group', 'extraction_type_class', 'management',\n",
    "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
    "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
    "       'source_class', 'waterpoint_type', 'waterpoint_type_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amount_tsh 70% value 0 which is unlikely\n",
    "#gps_height 34.4% value 0 which is unlikely. Same in Longitude and Latituse there is an overlap of 3.05%. Impute the with the mean of one of the geographical categorical values.\n",
    "#population 35.99% value 0 which is unlikely. Search for Population data from outsite sources\n",
    "#construction_year 34.8% value 0 which is unlikely. How can this be improved?\n",
    "#extraction_type, extraction_type_group, extraction_type_class have very similar values. Test using cramers_corrected_stat variable similariy\n",
    "\n",
    "#Longitude, 3.05% (same as Latitude) with a value of \"0\" which is highly unlikely, Since longitude is a highly imporatant variable, impute the mean of one of the giographical location such as basin or region code\n",
    "#Latitude, 3.05% (same as Longitude)with a value of \"0\" which is highly unlikely, Since longitude is a highly imporatant variable, impute the mean of one of the giographical location such as basin or region code\n",
    "\n",
    "#Disregard num_private with 98% value \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_corrected_stat(confusion_matrix):\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similars(cols, threshold=0.90):\n",
    "    for i1, col1 in enumerate(cols):\n",
    "        for i2, col2 in enumerate(cols):\n",
    "            if (i1<i2):\n",
    "                cm12 = pd.crosstab(train_data[col1], train_data[col2]).values # contingency table\n",
    "                cv12 = cramers_corrected_stat(cm12) # Cramer V statistic\n",
    "                if (cv12 > threshold):\n",
    "                    print((col1, col2), int(cv12*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_similars(grouping_col, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_data.copy()\n",
    "\n",
    "# #amount_tsh impute Functional value 0 for mean\n",
    "# amount_tsh_mean = train_temp.amount_tsh.mean()\n",
    "# amount_tsh_median = train_temp.amount_tsh.median()\n",
    "\n",
    "# #Impute values 0 with mean from amount_tsh where status_group == 'functional'\n",
    "# train_temp.amount_tsh = train_temp.amount_tsh.replace(0, amount_tsh_mean)\n",
    "\n",
    "# #Impute values 0 with mean from amount_tsh where status_group == 'functional'\n",
    "# train_temp.amount_tsh[train_temp.status_group == 'functional needs repair'] = train_temp.amount_tsh.replace(0, amount_repair_mean)\n",
    "\n",
    "# installer - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['DWE', 'Government','RWE','Commu','DANIDA']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.installer = train_temp.installer.map(replace)\n",
    "\n",
    "# funder - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['Government Of Tanzania',\n",
    "'Danida',\n",
    "'Hesawa',\n",
    "'Rwssp',\n",
    "'World Bank',\n",
    "'Kkkt',\n",
    "'World Vision',\n",
    "'Unicef',\n",
    "'Tasaf',\n",
    "'District Council']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.funder = train_temp.funder.map(replace)\n",
    "\n",
    "# lga - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['Njombe',\n",
    "'Arusha Rural',\n",
    "'Moshi Rural',\n",
    "'Bariadi',\n",
    "'Rungwe',\n",
    "'Kilosa',\n",
    "'Kasulu',\n",
    "'Mbozi',\n",
    "'Meru',\n",
    "'Bagamoyo']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.lga = train_temp.lga.map(replace)\n",
    "\n",
    "# extraction_type - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['gravity',\n",
    "'nira/tanira',\n",
    "'submersible',\n",
    "'swn 80',\n",
    "'mono',\n",
    "'india mark ii',\n",
    "'afridev',\n",
    "'ksb']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.extraction_type = train_temp.extraction_type.map(replace)\n",
    "\n",
    "# scheme_management - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list([\n",
    "'VWC',\n",
    "'WUG',\n",
    "'Water authority',\n",
    "'WUA',\n",
    "'Water Board',\n",
    "'Parastatal',\n",
    "'Private operator',\n",
    "'Company']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.scheme_management = train_temp.scheme_management.map(replace)\n",
    "\n",
    "# region_code - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list([11,17,12,3,5,18,19,2,16,10,4,1,13,14,20]):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "train_temp.region_code = train_temp.region_code.map(replace)\n",
    "\n",
    "\n",
    "#Eliminate scheme_name from the dataset.\n",
    "train_temp= train_temp.drop(columns=['scheme_name'])\n",
    "\n",
    "# Eliminate ward from dataset\n",
    "train_temp= train_temp.drop(columns=['ward'])\n",
    "\n",
    "# Eliminate wpt_name from dataset#\n",
    "train_temp= train_temp.drop(columns=['wpt_name'])\n",
    "\n",
    "# Eliminate subvillage from dataset#\n",
    "train_temp= train_temp.drop(columns=['subvillage'])\n",
    "\n",
    "#Choose Between Region and Region_Code and District Code\n",
    "#train_temp= train_temp.drop(columns=['region'])\n",
    "#train_temp= train_temp.drop(columns=['region_code'])\n",
    "#train_temp= train_temp.drop(columns=['district_code'])\n",
    "\n",
    "#Construction Year, Bin values per decade --- Note: that (-1, 1960] is the same as Unknown\n",
    "year_bins = [-1, 1960, 1990, 2015]\n",
    "train_temp['construction_year_bin'] = pd.cut(train_temp.construction_year,year_bins,labels=False, retbins=False, right=False)\n",
    "train_temp['construction_year_bin'] = train_temp[\"construction_year_bin\"].astype('category') \n",
    "train_temp= train_temp.drop(columns=['construction_year'])\n",
    "\n",
    "#how to treat, date_recorded?\n",
    "train_temp.date_recorded = pd.to_datetime(train_temp.date_recorded)\n",
    "train_temp.date_recorded = pd.to_datetime(train_temp.date_recorded)\n",
    "train_temp.date_recorded = pd.datetime(2014, 1, 1) - pd.to_datetime(train_temp.date_recorded)\n",
    "train_temp.columns = ['days_since_recorded' if x=='date_recorded' else x for x in train_temp.columns]\n",
    "train_temp.days_since_recorded = train_temp.days_since_recorded.astype('timedelta64[D]').astype(int)\n",
    "\n",
    "#recorded_bins = [1, 500, 1000, 2000, 4100]\n",
    "#train_temp['days_since_recorded_bin'] = pd.cut(train_temp.days_since_recorded,recorded_bins,labels=False, retbins=False, right=False)\n",
    "#train_temp['days_since_recorded_bin'] = train_temp[\"days_since_recorded_bin\"].astype('category') \n",
    "\n",
    "#Is longitude and Latitude relevant to the model\n",
    "# train_temp= train_temp.drop(columns=['longitude'])\n",
    "# train_temp= train_temp.drop(columns=['latitude'])\n",
    "\n",
    "#Decide between waterpoint_type & waterpoint_type_group\n",
    "# train_temp= train_temp.drop(columns=['waterpoint_type'])\n",
    "# train_temp= train_temp.drop(columns=['waterpoint_type_group'])\n",
    "\n",
    "#Decide between extraction_type & extraction_type_group & extraction_type_class\n",
    "# train_temp= train_temp.drop(columns=['extraction_type'])\n",
    "# train_temp= train_temp.drop(columns=['extraction_type_group'])\n",
    "# train_temp= train_temp.drop(columns=['extraction_type_class'])\n",
    "\n",
    "#Drop num_private with 98% of recors of values 0\n",
    "train_temp= train_temp.drop(columns=['num_private'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test_data.copy()\n",
    "\n",
    "# #amount_tsh impute Functional value 0 for mean\n",
    "# amount_tsh_mean = test_temp.amount_tsh.mean()\n",
    "# amount_tsh_median = test_temp.amount_tsh.median()\n",
    "\n",
    "# #Impute values 0 with mean from amount_tsh where status_group == 'functional'\n",
    "# test_temp.amount_tsh = test_temp.amount_tsh.replace(0, amount_tsh_mean)\n",
    "\n",
    "# #Impute values 0 with mean from amount_tsh where status_group == 'functional'\n",
    "# test_temp.amount_tsh[test_temp.status_group == 'functional needs repair'] = test_temp.amount_tsh.replace(0, amount_repair_mean)\n",
    "\n",
    "# installer - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['DWE', 'Government','RWE','Commu','DANIDA']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.installer = test_temp.installer.map(replace)\n",
    "\n",
    "# funder - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['Government Of Tanzania',\n",
    "'Danida',\n",
    "'Hesawa',\n",
    "'Rwssp',\n",
    "'World Bank',\n",
    "'Kkkt',\n",
    "'World Vision',\n",
    "'Unicef',\n",
    "'Tasaf',\n",
    "'District Council']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.funder = test_temp.funder.map(replace)\n",
    "\n",
    "# lga - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['Njombe',\n",
    "'Arusha Rural',\n",
    "'Moshi Rural',\n",
    "'Bariadi',\n",
    "'Rungwe',\n",
    "'Kilosa',\n",
    "'Kasulu',\n",
    "'Mbozi',\n",
    "'Meru',\n",
    "'Bagamoyo']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.lga = test_temp.lga.map(replace)\n",
    "\n",
    "# extraction_type - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list(['gravity',\n",
    "'nira/tanira',\n",
    "'submersible',\n",
    "'swn 80',\n",
    "'mono',\n",
    "'india mark ii',\n",
    "'afridev',\n",
    "'ksb']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.extraction_type = test_temp.extraction_type.map(replace)\n",
    "\n",
    "# scheme_management - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list([\n",
    "'VWC',\n",
    "'WUG',\n",
    "'Water authority',\n",
    "'WUA',\n",
    "'Water Board',\n",
    "'Parastatal',\n",
    "'Private operator',\n",
    "'Company']):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.scheme_management = test_temp.scheme_management.map(replace)\n",
    "\n",
    "# region_code - shortlist of the 5 higher and category other, note that nulls will be included in this criteria.\n",
    "def replace(x):\n",
    "    if x in list([11,17,12,3,5,18,19,2,16,10,4,1,13,14,20]):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "test_temp.region_code = test_temp.region_code.map(replace)\n",
    "\n",
    "\n",
    "#Eliminate scheme_name from the dataset.\n",
    "test_temp= test_temp.drop(columns=['scheme_name'])\n",
    "\n",
    "# Eliminate ward from dataset\n",
    "test_temp= test_temp.drop(columns=['ward'])\n",
    "\n",
    "# Eliminate wpt_name from dataset#\n",
    "test_temp= test_temp.drop(columns=['wpt_name'])\n",
    "\n",
    "# Eliminate subvillage from dataset#\n",
    "test_temp= test_temp.drop(columns=['subvillage'])\n",
    "\n",
    "#Choose Between Region and Region_Code and District Code\n",
    "#test_temp= test_temp.drop(columns=['region'])\n",
    "#test_temp= test_temp.drop(columns=['region_code'])\n",
    "#test_temp= test_temp.drop(columns=['district_code'])\n",
    "\n",
    "#Construction Year, Bin values per decade --- Note: that (-1, 1960] is the same as Unknown\n",
    "year_bins = [-1, 1960, 1990, 2015]\n",
    "test_temp['construction_year_bin'] = pd.cut(test_temp.construction_year,year_bins,labels=False, retbins=False, right=False)\n",
    "test_temp['construction_year_bin'] = test_temp[\"construction_year_bin\"].astype('category') \n",
    "test_temp= test_temp.drop(columns=['construction_year'])\n",
    "\n",
    "#how to treat, date_recorded?\n",
    "test_temp.date_recorded = pd.to_datetime(test_temp.date_recorded)\n",
    "test_temp.date_recorded = pd.to_datetime(test_temp.date_recorded)\n",
    "test_temp.date_recorded = pd.datetime(2014, 1, 1) - pd.to_datetime(test_temp.date_recorded)\n",
    "test_temp.columns = ['days_since_recorded' if x=='date_recorded' else x for x in test_temp.columns]\n",
    "test_temp.days_since_recorded = test_temp.days_since_recorded.astype('timedelta64[D]').astype(int)\n",
    "\n",
    "#recorded_bins = [1, 500, 1000, 2000, 4100]\n",
    "#test_temp['days_since_recorded_bin'] = pd.cut(test_temp.days_since_recorded,recorded_bins,labels=False, retbins=False, right=False)\n",
    "#test_temp['days_since_recorded_bin'] = test_temp[\"days_since_recorded_bin\"].astype('category') \n",
    "\n",
    "#Is longitude and Latitude relevant to the model\n",
    "# test_temp= test_temp.drop(columns=['longitude'])\n",
    "# test_temp= test_temp.drop(columns=['latitude'])\n",
    "\n",
    "#Decide between waterpoint_type & waterpoint_type_group\n",
    "# test_temp= test_temp.drop(columns=['waterpoint_type'])\n",
    "# test_temp= test_temp.drop(columns=['waterpoint_type_group'])\n",
    "\n",
    "#Decide between extraction_type & extraction_type_group & extraction_type_class\n",
    "# test_temp= test_temp.drop(columns=['extraction_type'])\n",
    "# test_temp= test_temp.drop(columns=['extraction_type_group'])\n",
    "# test_temp= test_temp.drop(columns=['extraction_type_class'])\n",
    "\n",
    "#Drop num_private with 98% of recors of values 0\n",
    "test_temp= test_temp.drop(columns=['num_private'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Train Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp['district_code'] = train_temp[\"district_code\"].astype('category') \n",
    "train_temp['region_code'] = train_temp[\"region_code\"].astype('category') \n",
    "\n",
    "train_temp['funder'] = train_temp[\"funder\"].astype('category') \n",
    "train_temp['installer'] = train_temp[\"installer\"].astype('category') \n",
    "train_temp['lga'] = train_temp[\"lga\"].astype('category') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Test Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp['district_code'] = test_temp[\"district_code\"].astype('category') \n",
    "test_temp['region_code'] = test_temp[\"region_code\"].astype('category') \n",
    "\n",
    "test_temp['funder'] = test_temp[\"funder\"].astype('category') \n",
    "test_temp['installer'] = test_temp[\"installer\"].astype('category') \n",
    "test_temp['lga'] = test_temp[\"lga\"].astype('category') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns)))\n",
    "\n",
    "def onehot_encode(df):\n",
    "    numericals = df.get(numerical_features(df))\n",
    "    new_df = numericals.copy()\n",
    "    for categorical_column in categorical_features(df):\n",
    "        new_df = pd.concat([new_df, \n",
    "                            pd.get_dummies(df[categorical_column], \n",
    "                                           prefix=categorical_column)], \n",
    "                           axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_skewness(df):\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    numeric_features = []\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype in numeric_dtypes: \n",
    "            numeric_features.append(i)\n",
    "\n",
    "    feature_skew = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':feature_skew})\n",
    "    return feature_skew, numeric_features,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_skewness(test_temp)\n",
    "feature_skewness(train_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_skewness(df):\n",
    "    feature_skew, numeric_features = feature_skewness(df)\n",
    "    high_skew = feature_skew[feature_skew > 0.75]\n",
    "    skew_index = high_skew.index\n",
    "    \n",
    "    for i in skew_index:\n",
    "        df[i] = boxcox1p(df[i], boxcox_normmax(df[i]+1))\n",
    "\n",
    "    skew_features = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':skew_features})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_skewness(test_temp)\n",
    "fix_skewness(train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_numeric_features = test_temp[['amount_tsh','days_since_recorded','gps_height','num_private','population']]\n",
    "# train_numeric_features = train_temp[['amount_tsh','days_since_recorded','gps_height','num_private','population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# temp = numeric_features\n",
    "# norm_temp = scaler.fit_transform(temp)\n",
    "# numeric_features = pd.DataFrame(norm_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_numeric_features.columns = ['amount_tsh','days_since_recorded','gps_height','num_private','population']\n",
    "# train_numeric_features.columns = ['amount_tsh','days_since_recorded','gps_height','num_private','population']\n",
    "# train_numeric_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_temp = test_temp.drop(columns=['amount_tsh','days_since_recorded','gps_height','num_private','population'])\n",
    "# train_temp = train_temp.drop(columns=['amount_tsh','days_since_recorded','gps_height','num_private','population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_temp = test_numeric_features.join(test_temp)\n",
    "# train_temp = train_numeric_features.join(train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_temp = train_temp.join(train_labels)\n",
    "#Drop id and recorded from train dataset \n",
    "# train_temp= train_temp.drop(columns=['id'])\n",
    "# train_temp= train_temp.drop(columns=['recorded_by'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate trainning labels from data set \n",
    "train_temp.status_group.replace(['functional', 'non functional','functional needs repair'], [1, 2, 3], inplace=True)\n",
    "train_labels = train_temp['status_group']\n",
    "train_temp= train_temp.drop(columns=['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data frames before the baseline\n",
    "train_set = onehot_encode(train_temp)\n",
    "test_set = onehot_encode(test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels\n",
    "train_set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_set, train_labels, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randon Forest - Under 2 minutes\n",
    "rf = RFC(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy:', rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost - Under 4 minutes Simple Model / Complex 25 min\n",
    "\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "#                       learning_rate= 0.075,\n",
    "#                       max_depth= 6,\n",
    "#                       min_samples_leaf= 16,\n",
    "#                       subsample= 0.8,\n",
    "#                       max_features= 1.0,\n",
    "#                       n_estimators= 1000,\n",
    "#                       gamma=1)\n",
    "#Accuracy: 0.8064814814814815\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "#                       learning_rate= 0.025,\n",
    "#                       max_depth= 6,\n",
    "#                       min_samples_leaf= 16,\n",
    "#                       subsample= 0.8,\n",
    "#                       max_features= 1.0,\n",
    "#                       n_estimators= 1000,\n",
    "#                       gamma=1)\n",
    "#Accuracy: 0.7962121212121213\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "#                       learning_rate= 0.025,\n",
    "#                       max_depth= 6,\n",
    "#                       min_samples_leaf= 16,\n",
    "#                       subsample= 0.8,\n",
    "#                       max_features= 1.0,\n",
    "#                       n_estimators= 1000,\n",
    "#                       gamma=1)\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "#                       learning_rate= 1,\n",
    "#                       max_depth= 6,\n",
    "#                       min_samples_leaf= 16,\n",
    "#                       subsample= 0.8,\n",
    "#                       max_features= 1.0,\n",
    "#                       n_estimators= 1000,\n",
    "#                       gamma=1)\n",
    "#Accuracy: 0.7920875420875421\n",
    "# xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "#                       learning_rate= 0.08,\n",
    "#                       max_depth= 6,\n",
    "#                       min_samples_leaf= 16,\n",
    "#                       subsample= 0.8,\n",
    "#                       max_features= 1.0,\n",
    "#                       n_estimators= 1000,\n",
    "#                       gamma=1)\n",
    "# Accuracy: 0.8074074074074075 - xgb_v2\n",
    "xgb_model = XGBClassifier(objective=\"multi:softprob\",\n",
    "                      learning_rate= 0.08,\n",
    "                      max_depth= 8,\n",
    "                      min_samples_leaf= 16,\n",
    "                      subsample= 0.8,\n",
    "                      max_features= 1.0,\n",
    "                      n_estimators= 1000,\n",
    "                      gamma=1)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_score = xgb_model.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy:', xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "# #eval_metric = [\"auc\",\"error\"]\n",
    "# eval_metric = \"mlogloss\"\n",
    "# %time xgb_model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.pyplot.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(xgb_model, (10,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(X_train, X_test, y_train, y_test):\n",
    "#     if __name__ == '__main__':\n",
    "    \n",
    "#         param_grid = {'learning_rate': [0.075, 0.05, 0.025],\n",
    "#                       'max_depth': [4, 6, 8],\n",
    "#                       'min_samples_leaf': [15, 16],\n",
    "#                       'subsample': [0.8, 0.9, 1],\n",
    "#                       'max_features': [1.0],\n",
    "#                       'n_estimators': [1000, 500, 100],\n",
    "#                       'gamma':[0,1,5]}                      \n",
    "\n",
    "#         estimator = GridSearchCV(estimator=XGBClassifier(objective=\"multi:softprob\", random_state=42),\n",
    "#                                  param_grid=param_grid,\n",
    "#                                  n_jobs=-1)\n",
    "\n",
    "#         estimator.fit(X_train, y_train)\n",
    "\n",
    "#         best_params = estimator.best_params_\n",
    "\n",
    "#         print (best_params)\n",
    "                                 \n",
    "#         validation_accuracy = estimator.score(X_test, y_test)\n",
    "#         print('Validation accuracy: ', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(X_train, X_test, y_train, y_test):\n",
    "#     if __name__ == '__main__':\n",
    "    \n",
    "#         param_grid = {'learning_rate': [0.075],\n",
    "#                       'max_depth': [8],\n",
    "#                       'min_samples_leaf': [16],\n",
    "#                       'subsample': [0.8],\n",
    "#                       'max_features': [1.0],\n",
    "#                       'n_estimators': [1000],\n",
    "#                       'gamma':[1]}                      \n",
    "\n",
    "#         estimator = GridSearchCV(estimator=XGBClassifier(objective=\"multi:softprob\", random_state=42),\n",
    "#                                  param_grid=param_grid,\n",
    "#                                  n_jobs=-1)\n",
    "\n",
    "#         estimator.fit(X_train, y_train)\n",
    "\n",
    "#         best_params = estimator.best_params_\n",
    "\n",
    "#         print (best_params)\n",
    "                                 \n",
    "#         validation_accuracy = estimator.score(X_test, y_test)\n",
    "#         print('Validation accuracy: ', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_for_submission(features, target, test):\n",
    "#     if __name__ == '__main__':\n",
    "\n",
    "#          best_params = {'learning_rate': [0.075],\n",
    "#                         'max_depth': [14],\n",
    "#                         'min_samples_leaf': [16],\n",
    "#                         'max_features': [1.0],\n",
    "#                         'n_estimators': [100]}                      \n",
    "\n",
    "#          estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "#                                  param_grid=best_params,\n",
    "#                                  n_jobs=-1)\n",
    "\n",
    "#          estimator.fit(features, target)     \n",
    "\n",
    "#          predictions = estimator.predict(test)\n",
    "\n",
    "#          data = {'ID': test_id, 'status_group': predictions}\n",
    "\n",
    "#          submit = pd.DataFrame(data=data)\n",
    "\n",
    "#          vals_to_replace = {1:'functional', 2:'functional needs repair',\n",
    "#                            3:'non functional'}\n",
    "\n",
    "#          submit.status_group = submit.status_group.replace(vals_to_replace)        \n",
    "\n",
    "#          submit.to_csv('pump_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model):    \n",
    "\n",
    "         predictions = model.predict(test_set)\n",
    "\n",
    "         data = {'ID': test_id, 'status_group': predictions}\n",
    "\n",
    "         submit = pd.DataFrame(data=data)\n",
    "\n",
    "         vals_to_replace = {1:'functional',2:'non functional',3:'functional needs repair'}\n",
    "\n",
    "         submit.status_group = submit.status_group.replace(vals_to_replace)        \n",
    "\n",
    "         submit.to_csv('pump_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "rfe = RFE(rf)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function out of normalizing\n",
    "X_train_after_rfe = X_train.iloc[:,fit.support_].copy()\n",
    "X_train_after_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform target variable into categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does performing PCA make sense?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
