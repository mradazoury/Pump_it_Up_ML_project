{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Packages & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_prep\n",
    "%run data_prep.py\n",
    "%aimport modeling\n",
    "%run modeling.py\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-097416459219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load Datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./FE_Final/train_data_prepared.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./original_datasets/training_set_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status_group\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./FE_Final/test_data_prepared.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Load Datasets\n",
    "dataset = pd.read_csv(\"./FE_Final/train_data_prepared.csv\")\n",
    "train_data = dataset[dataset.is_test == 0]\n",
    "target = pd.read_csv(\"./original_datasets/training_set_labels.csv\")\n",
    "target=target[[\"status_group\"]]\n",
    "\n",
    "train_data  = train_data.drop(['subvillage','date_recorded','wpt_name','recorded_by','is_test'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>density</th>\n",
       "      <th>age</th>\n",
       "      <th>Flag_age</th>\n",
       "      <th>Flag_date_recorded</th>\n",
       "      <th>days_since_recoreded</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>1390</td>\n",
       "      <td>other</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2901.0, 2920.0]</td>\n",
       "      <td>1783.545310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>1399</td>\n",
       "      <td>other</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>...</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1923.999, 2196.0]</td>\n",
       "      <td>931.445791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>other</td>\n",
       "      <td>686</td>\n",
       "      <td>other</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>...</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2196.0, 2221.0]</td>\n",
       "      <td>1126.306889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>other</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>...</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2221.0, 2241.0]</td>\n",
       "      <td>1949.338824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>...</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.389401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(2790.0, 2901.0]</td>\n",
       "      <td>1025.769078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh  funder  gps_height installer  longitude   latitude  \\\n",
       "0  69572      6000.0   other        1390     other  34.938093  -9.856322   \n",
       "1   8776         0.0   other        1399     other  34.698766  -2.147466   \n",
       "2  34310        25.0   other         686     other  37.460664  -3.821329   \n",
       "3  67743         0.0  Unicef         263     other  38.486161 -11.155298   \n",
       "4  19728         0.0   other           0     other  31.130847  -1.825359   \n",
       "\n",
       "   num_private                    basin   region     ...       \\\n",
       "0            0               Lake Nyasa   Iringa     ...        \n",
       "1            0            Lake Victoria     Mara     ...        \n",
       "2            0                  Pangani  Manyara     ...        \n",
       "3            0  Ruvuma / Southern Coast   Mtwara     ...        \n",
       "4            0            Lake Victoria   Kagera     ...        \n",
       "\n",
       "            source_type  source_class              waterpoint_type  \\\n",
       "0                spring   groundwater           communal standpipe   \n",
       "1  rainwater harvesting       surface           communal standpipe   \n",
       "2                   dam       surface  communal standpipe multiple   \n",
       "3              borehole   groundwater  communal standpipe multiple   \n",
       "4  rainwater harvesting       surface           communal standpipe   \n",
       "\n",
       "  waterpoint_type_group   density        age Flag_age Flag_date_recorded  \\\n",
       "0    communal standpipe  0.000116  20.000000        0                  0   \n",
       "1    communal standpipe  0.000161   9.000000        0                  0   \n",
       "2    communal standpipe  0.000175  10.000000        0                  0   \n",
       "3    communal standpipe  0.000046  33.000000        0                  0   \n",
       "4    communal standpipe  0.000000  14.389401        1                  0   \n",
       "\n",
       "  days_since_recoreded     distance  \n",
       "0     (2901.0, 2920.0]  1783.545310  \n",
       "1   (1923.999, 2196.0]   931.445791  \n",
       "2     (2196.0, 2221.0]  1126.306889  \n",
       "3     (2221.0, 2241.0]  1949.338824  \n",
       "4     (2790.0, 2901.0]  1025.769078  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 42 columns):\n",
      "id                       59400 non-null int64\n",
      "amount_tsh               59400 non-null float64\n",
      "funder                   59400 non-null object\n",
      "gps_height               59400 non-null int64\n",
      "installer                59400 non-null object\n",
      "longitude                59400 non-null float64\n",
      "latitude                 59400 non-null float64\n",
      "num_private              59400 non-null int64\n",
      "basin                    59400 non-null object\n",
      "region                   59400 non-null object\n",
      "region_code              59400 non-null int64\n",
      "district_code            59400 non-null int64\n",
      "lga                      59400 non-null object\n",
      "ward                     59400 non-null object\n",
      "population               59400 non-null int64\n",
      "public_meeting           56066 non-null object\n",
      "scheme_management        59400 non-null object\n",
      "scheme_name              31234 non-null object\n",
      "permit                   56344 non-null object\n",
      "construction_year        59400 non-null int64\n",
      "extraction_type          59400 non-null object\n",
      "extraction_type_group    59400 non-null object\n",
      "extraction_type_class    59400 non-null object\n",
      "management               59400 non-null object\n",
      "management_group         59400 non-null object\n",
      "payment                  59400 non-null object\n",
      "payment_type             59400 non-null object\n",
      "water_quality            59400 non-null object\n",
      "quality_group            59400 non-null object\n",
      "quantity                 59400 non-null object\n",
      "quantity_group           59400 non-null object\n",
      "source                   59400 non-null object\n",
      "source_type              59400 non-null object\n",
      "source_class             59400 non-null object\n",
      "waterpoint_type          59400 non-null object\n",
      "waterpoint_type_group    59400 non-null object\n",
      "density                  59400 non-null float64\n",
      "age                      59400 non-null float64\n",
      "Flag_age                 59400 non-null int64\n",
      "Flag_date_recorded       59400 non-null int64\n",
      "days_since_recoreded     59400 non-null object\n",
      "distance                 59400 non-null float64\n",
      "dtypes: float64(6), int64(9), object(27)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features before: 42\n",
      "# of features after: 4999\n"
     ]
    }
   ],
   "source": [
    "train_data_trees = train_data.copy()\n",
    "train_data_lr = train_data.copy()\n",
    "\n",
    "train_label_encode = label_encoder(train_data_trees)\n",
    "train_onehot_encode = onehot_encode(train_data_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8121212121212121\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_label_encode, target, train_size=0.8)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy:', rf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7455387205387205\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(objective=\"multi:softprob\")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_score = xgb_model.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy:', xgb_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class logReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>...</th>\n",
       "      <th>extraction_type_group_wind-powered</th>\n",
       "      <th>scheme_management_Company</th>\n",
       "      <th>scheme_management_Parastatal</th>\n",
       "      <th>scheme_management_Private operator</th>\n",
       "      <th>scheme_management_VWC</th>\n",
       "      <th>scheme_management_WUA</th>\n",
       "      <th>scheme_management_WUG</th>\n",
       "      <th>scheme_management_Water Board</th>\n",
       "      <th>scheme_management_Water authority</th>\n",
       "      <th>scheme_management_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>1986</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh  gps_height  longitude   latitude  num_private  \\\n",
       "0  69572      6000.0        1390  34.938093  -9.856322            0   \n",
       "1   8776         0.0        1399  34.698766  -2.147466            0   \n",
       "2  34310        25.0         686  37.460664  -3.821329            0   \n",
       "3  67743         0.0         263  38.486161 -11.155298            0   \n",
       "4  19728         0.0           0  31.130847  -1.825359            0   \n",
       "\n",
       "   region_code  district_code  population  construction_year  \\\n",
       "0           11              5         109               1999   \n",
       "1           20              2         280               2010   \n",
       "2            0              4         250               2009   \n",
       "3            0             63          58               1986   \n",
       "4           18              1           0                  0   \n",
       "\n",
       "            ...             extraction_type_group_wind-powered  \\\n",
       "0           ...                                              0   \n",
       "1           ...                                              0   \n",
       "2           ...                                              0   \n",
       "3           ...                                              0   \n",
       "4           ...                                              0   \n",
       "\n",
       "   scheme_management_Company  scheme_management_Parastatal  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "\n",
       "   scheme_management_Private operator  scheme_management_VWC  \\\n",
       "0                                   0                      1   \n",
       "1                                   0                      0   \n",
       "2                                   0                      1   \n",
       "3                                   0                      1   \n",
       "4                                   0                      0   \n",
       "\n",
       "   scheme_management_WUA  scheme_management_WUG  \\\n",
       "0                      0                      0   \n",
       "1                      0                      0   \n",
       "2                      0                      0   \n",
       "3                      0                      0   \n",
       "4                      0                      0   \n",
       "\n",
       "   scheme_management_Water Board  scheme_management_Water authority  \\\n",
       "0                              0                                  0   \n",
       "1                              0                                  0   \n",
       "2                              0                                  0   \n",
       "3                              0                                  0   \n",
       "4                              0                                  0   \n",
       "\n",
       "   scheme_management_other  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        1  \n",
       "\n",
       "[5 rows x 4999 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_onehot_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7207912457912458\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_onehot_encode, target, train_size=0.8)\n",
    "\n",
    "clf = LogisticRegression(multi_class=\"ovr\").fit(train_onehot_encode, target)\n",
    "clf_Score = clf.score(X_test,y_test)\n",
    "print('Accuracy:', clf_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only latitude and longitude and height were used in order to try and see if there is a relationship  between the location of the well and the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_label_encode[['latitude','longitude']], target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680050505050505"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
    "           weights='uniform')\n",
    "\n",
    "neighbors =  knn.fit(X_train, y_train)\n",
    "neighbors.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Grid Search for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best parameters will be used to output a result for the different combination of feature creation and imputing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./original_datasets/initial_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data\n",
    "to_int = {'functional':1,'non functional':2,'functional needs repair':3}\n",
    "to_cat = {1:'functional',2:'non functional',3:'functional needs repair'}\n",
    "\n",
    "y_Train = dataset['status_group'].loc[(dataset['is_test'].isin([0]) )]\n",
    "y   = y_Train.replace(to_int).copy()\n",
    "dataset = dataset.drop('status_group',axis=1).copy()\n",
    "   \n",
    "    ### Label encode\n",
    "dataset = label_encoder(dataset).copy()\n",
    "    ### Divide test and train \n",
    "X_Train= dataset.loc[(dataset['is_test'].isin([0]) )].drop('is_test',axis=1)\n",
    "test = dataset.loc[(dataset['is_test'].isin([1]) )].drop(['is_test'],axis=1)\n",
    "\n",
    "    #### Set ID aside for test \n",
    "ID = test['id'] \n",
    "\n",
    "    ### If train_id set to Trues the the ID will be kept as feature\n",
    "\n",
    "X = X_Train.set_index('id')\n",
    "test = test.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_parameters = {'n_estimators': [100,200 ],\n",
    "                                             'bootstrap': [True,False],\n",
    "                                             'max_depth': [80, 100 ,120],\n",
    "                                             'max_features': ['auto',16 ,32],\n",
    "                                             'min_samples_leaf': [ 2,  5 ],\n",
    "                                             'min_samples_split': [ 5,  8 ],\n",
    "                                            'random_state':[random_seed],\n",
    "                                                'n_jobs':[-1]}\n",
    "rf = GridSearchCV(RandomForestClassifier(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=KFold(3,random_state = random_seed),verbose = True,n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(X, y)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=80, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=6666, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.best_estimator_.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Grid Search on XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following parameters will be defined to any XGBoost used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.01, 0.1], \n",
    "          'max_depth': [4,8,12],\n",
    "          'min_child_weight': [3,5,10,20,35,50],\n",
    "          'subsample': [0.5, 0.75],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [100, 300],\n",
    "              'random_state':[random_seed]\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "to_int = {'functional':1,'non functional':2,'functional needs repair':3}\n",
    "to_cat = {1:'functional',2:'non functional',3:'functional needs repair'}\n",
    "\n",
    "y_Train = dataset['status_group'].loc[(dataset['is_test'].isin([0]) )]\n",
    "y_Train   = y_Train.replace(to_int).copy()\n",
    "dataset = dataset.drop('status_group',axis=1).copy()\n",
    "   \n",
    "    ### Label encode\n",
    "dataset = label_encoder(dataset).copy()\n",
    "    ### Divide test and train \n",
    "X_Train= dataset.loc[(dataset['is_test'].isin([0]) )].drop('is_test',axis=1)\n",
    "test = dataset.loc[(dataset['is_test'].isin([1]) )].drop(['is_test'],axis=1)\n",
    "\n",
    "    #### Set ID aside for test \n",
    "ID = test['id'] \n",
    "\n",
    "    ### If train_id set to Trues the the ID will be kept as feature\n",
    "\n",
    "X_Train = X_Train.set_index('id')\n",
    "test = test.set_index('id')\n",
    "\n",
    "xg = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = KFold(5,random_state=random_seed),\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'accuracy',\n",
    "                    verbose=True)\n",
    "xg.fit(X_Train,y_Train)\n",
    "print(xg.cv_results_)\n",
    "print(xg.best_params_)\n",
    "print(xg.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier(subsample= 0.75, random_state=random_seed,\n",
    "         n_estimators =  300, min_child_weight= 20, \n",
    "         max_depth=90, learning_rate= 0.1, colsample_bytree= 0.75,  n_jobs=-1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    " Xll = data[['longitude','latitude']]\n",
    "yll = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_parameters = {'n_neighbors':[1, 5,10,15 ],'weights':['uniform'], 'algorithm':['auto'],'leaf_size':[5 ,10, 20],\n",
    "                  'p':[1,2,3],'metric':['minkowski']}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),verbose =True,\n",
    "                                 param_grid=knn_parameters,\n",
    "                                 cv=KFold(5,random_state = 42),return_train_score=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xll, yll, random_state=42)\n",
    "knn.fit(Xll, yll)\n",
    "knn.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:darkred\"> Scores for Random Forest Tried on diffrent combinations of features and imputing, Cross validation Scores are printed and the prediction directly saved to a file really for submission </P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset : 'Initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8148653198653198\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./original_datasets/initial_joined.csv\")\n",
    "scores , preds = test_score(data ,'initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'imputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8153198653198654\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"./FE_steps/1 train_data_imputed.csv\")\n",
    "scores1 , preds1 = test_score(data1 ,'1 train_data_imputed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'impute_age_days_recorded_density_PTR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8143602693602695\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"./FE_steps/2 train_data_impute_age_dayse_recorded_density.csv\")\n",
    "scores2 , preds2 = test_score(data2 ,'2 train_data_impute_age_days_recorded_density_PTR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'NOIMPUTE_age_days_recorded_density_PTR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8144612794612796\n"
     ]
    }
   ],
   "source": [
    "data3 = pd.read_csv(\"./FE_steps/3 train_data_NOIMPUTE_age_dayse_recorded_density.csv\")\n",
    "scores3 , preds3 = test_score(data3 ,'3 train_data_NOIMPUTE_age_days_recorded_density_PTR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'NOIMPUTE_age_days_recorded_density_capital_PTR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.815959595959596\n"
     ]
    }
   ],
   "source": [
    "data4 = pd.read_csv(\"./FE_steps/4 train_data_NOIMPUTE_age_dayse_recorded_density_capital.csv\")\n",
    "scores4 , preds4 = test_score(data4 ,'4 train_data_NOIMPUTE_age_days_recorded_density_capital_PTR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'NOIMPUTE_age_dayse_recorded_density_capital_SHORTLISTING.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8154040404040404\n"
     ]
    }
   ],
   "source": [
    "data5 = pd.read_csv(\"./FE_steps/5 train_data_NOIMPUTE_age_dayse_recorded_density_capital_SHORTLISTING.csv\")\n",
    "scores5 , preds5 = test_score(data5 ,'5 train_data_NOIMPUTE_age_dayse_recorded_density_capital_SHORTLISTING_PTR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset :'gps_height_ONLY_imputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8154545454545454\n"
     ]
    }
   ],
   "source": [
    "data6 = pd.read_csv(\"./FE_steps/6 train_data_gps_height_ONLY_imputed.csv\")\n",
    "scores6 , preds6 = test_score(data6 ,'6 train_data_gps_height_ONLY_imputed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset :'capital_ONLY_latitude_longitude_PTR' <p style=\"color:red\">This is our best score which is used for submission</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the cross validation with Random Forest:0.8162962962962963\n"
     ]
    }
   ],
   "source": [
    "data7 = pd.read_csv(\"./FE_steps/7 train_data_capital_ONLY.csv\")\n",
    "scores7 , preds7 = test_score(data7 ,'7 train_data_capital_ONLY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen here all of them have an acceptable score due to the parameters used from the best estimator of grid search , after testing  the highest score was with prediction 7 which includes the imputings ogf latitude and longitude, PTR (pupil per teacher) and Distance to capital.\n",
    "#### Now in order to increase the score  7 predictions from each of the above datasets will be done on the train set in a kfold manner, predicting on the left out for each of the folds.\n",
    "#### These 7 new predictions will now become features for a new model. This new model will train on the 7 predictions of the initial train set and will predict from the 7 predictions made on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = { 'data': data , 'data1' : data1 , 'data2':data2 , 'data3':data3 , 'data4': data4 , 'data5':data5\n",
    "            , 'data6':data6 , 'data7':data7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =    [ RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "            oob_score=False, random_state=random_seed, verbose=1, warm_start=False)]\n",
    "S_train ={}\n",
    "S_test = {}\n",
    "for i in datasets:\n",
    "    dataset = datasets[i]\n",
    "    to_int = {'functional':1,'non functional':2,'functional needs repair':3}\n",
    "    to_cat = {1:'functional',2:'non functional',3:'functional needs repair'}\n",
    "\n",
    "    y_Train = dataset['status_group'].loc[(dataset['is_test'].isin([0]) )]\n",
    "    y_Train   = y_Train.replace(to_int).copy()\n",
    "    dataset = dataset.drop('status_group',axis=1).copy()\n",
    "   \n",
    "    ### Label encode\n",
    "    dataset = label_encoder(dataset).copy()\n",
    "    ### Divide test and train \n",
    "    X_Train= dataset.loc[(dataset['is_test'].isin([0]) )].drop('is_test',axis=1)\n",
    "    test = dataset.loc[(dataset['is_test'].isin([1]) )].drop(['is_test'],axis=1)\n",
    "\n",
    "    #### Set ID aside for test \n",
    "    ID = test['id'] \n",
    "\n",
    "    ### If train_id set to Trues the the ID will be kept as feature\n",
    "\n",
    "    X_Train = X_Train.set_index('id')\n",
    "    test = test.set_index('id')\n",
    "    \n",
    "    S_train[i], S_test[i] = stacking(model,                     # list of models\n",
    "                           X_Train, y_Train, test,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=5,                  # number of folds\n",
    "                           stratified=False,            # stratified split for folds\n",
    "                           shuffle=False,               # shuffle the data\n",
    "                           random_state=random_seed,\n",
    "                                    verbose =2)                  # print all info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking the Train and test predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpred=pd.DataFrame(columns= ['data', 'data1'  , 'data2' , 'data3' , 'data4', 'data5'\n",
    "            , 'data6' , 'data7'])\n",
    "testp=pd.DataFrame(columns= ['data', 'data1'  , 'data2' , 'data3' , 'data4', 'data5'\n",
    "            , 'data6' , 'data7'])\n",
    "for i in S_train :\n",
    "    tpred[i]=[int(x) for x in S_train[i]]\n",
    "for i in S_test :\n",
    "    testp[i]=[int(x) for x in S_test[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost classifier with paramerters obtained from a previous GridSearch trained on the prediction of the 8 random forests form each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=12, min_child_weight=3, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "       random_state=6666, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.5, verbose=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbs = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=12, min_child_weight=3, missing=None, n_estimators=150,\n",
    "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
    "       random_state=random_seed, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=0.5, verbose=True)  \n",
    "xgbs.fit(tpred, y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting from the stacked test predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredictionsall = xgbs.predict(testp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {'ID': ID, 'status_group': testpredictionsall}\n",
    "submit = pd.DataFrame(data=data)\n",
    "submit['status_group'] = submit.status_group.replace(to_cat)\n",
    "submit.to_csv('predictions/allstack8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"color:darkred\"> This yielded a score of 0.8185 on the compitetion , which is worst then the previous scores , so this techinique did not help </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above stacking did not help improve our score , a different way of stacking will now be used.On the train dataset 5 , which gave on the highest score , an XGBClassifier and RandomForesct will train and predict on the train set and as earlier use the cross validation folds to fill the train prediction. These two prediction will be stacked and another XGBClassifier will be trained and will predict on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    XGBClassifier(subsample= 0.75, random_state=random_seed,\n",
    "         n_estimators =  300, min_child_weight= 20, \n",
    "         max_depth=90, learning_rate= 0.1, colsample_bytree= 0.75,  n_jobs=-1, verbose = True),\n",
    "        \n",
    "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=random_seed, verbose=1, warm_start=False)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_int = {'functional':1,'non functional':2,'functional needs repair':3}\n",
    "to_cat = {1:'functional',2:'non functional',3:'functional needs repair'}\n",
    "\n",
    "y_Train = data5['status_group'].loc[(data5['is_test'].isin([0]) )]\n",
    "y_Train   = y_Train.replace(to_int).copy()\n",
    "dataset = data5.drop('status_group',axis=1).copy()\n",
    "   \n",
    "    ### Label encode\n",
    "data5 = label_encoder(data5).copy()\n",
    "    ### Divide test and train \n",
    "X_Train= data5.loc[(data5['is_test'].isin([0]) )].drop('is_test',axis=1)\n",
    "test = data5.loc[(data5['is_test'].isin([1]) )].drop(['is_test'],axis=1)\n",
    "\n",
    "    #### Set ID aside for test \n",
    "ID = test['id'] \n",
    "\n",
    "    ### If train_id set to Trues the the ID will be kept as feature\n",
    "\n",
    "X_Train = X_Train.set_index('id')\n",
    "test = test.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    fold  0:  [0.81111111]\n",
      "    fold  1:  [0.80513468]\n",
      "    fold  2:  [0.80530303]\n",
      "    fold  3:  [0.81380471]\n",
      "    fold  4:  [0.81304714]\n",
      "    ----\n",
      "    MEAN:     [0.80968013] + [0.00374745]\n",
      "    FULL:     [0.80968013]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.81161616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.80993266]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.80690236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.81489899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.81666667]\n",
      "    ----\n",
      "    MEAN:     [0.81200337] + [0.00348106]\n",
      "    FULL:     [0.81200337]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "St_train, St_test = stacking(models,                     # list of models\n",
    "                           X_Train, y_Train, test,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=5,                  # number of folds\n",
    "                           stratified=False,            # stratified split for folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=random_seed,             # ensure reproducibility\n",
    "                           verbose=2)                  # print all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbst = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=12, min_child_weight=3, missing=None, n_estimators=150,\n",
    "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
    "       random_state=random_seed, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=0.5, verbose=True)  \n",
    "NX_Train = pd.DataFrame(St_train)\n",
    "\n",
    "scores= cross_val_score(xbst, \n",
    "                NX_Train, y_Train,scoring='accuracy', cv=KFold(5,random_state= random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "NX_Train = pd.DataFrame(S_train)\n",
    "test = pd.DataFrame(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=12, min_child_weight=3, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "       random_state=6666, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.5, verbose=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbst.fit(NX_Train, y_Train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score of 2nd stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812003367003367"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbst.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpt = xgbs.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ID': ID, 'status_group': testp]}\n",
    "submit = pd.DataFrame(data=data)\n",
    "submit['status_group'] = submit.status_group.replace(to_cat)\n",
    "submit.to_csv('predictions/stack2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This stacking as well still did not help to improve the predictions on the pump it up challenge , it seemed more relevant to take the random forest trained on test set 5 since it had the highest accuracy and many of the features created were relevant in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final score on the sumission on the website is 82.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
