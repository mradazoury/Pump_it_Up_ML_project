{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_prep\n",
    "%run data_prep.py\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets & Join both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"original_datasets/training_set_values.csv\")\n",
    "train_labels = pd.read_csv(\"original_datasets/training_set_labels.csv\")\n",
    "test_data = pd.read_csv(\"original_datasets/test_set_values.csv\")\n",
    "\n",
    "#Join Labels with Train data\n",
    "train_data = addLabelToTrainData(train_data, train_labels)\n",
    "test_data['status_group'] = 'test'\n",
    "#test_data.insert(0, 'My 2nd new column', 'default value 2')\n",
    "train_data['is_test'] = 0\n",
    "test_data['is_test'] = 1\n",
    "\n",
    "data = pd.concat([train_data,test_data],ignore_index=True)\n",
    "data.to_csv('./original_datasets/initial_joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Transformoing on a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'impute_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-bdf35049ca5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Impute Latitude by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpute_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gps_height\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_transformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./FE_steps/6 train_data_gps_height_ONLY_imputed.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'impute_column' is not defined"
     ]
    }
   ],
   "source": [
    "#Impute Latitude by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\n",
    "data_transformed = impute_column(data_transformed, \"gps_height\")\n",
    "data_transformed.to_csv(\"./FE_steps/6 train_data_gps_height_ONLY_imputed.csv\", index=False)\n",
    "data_transformed = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude imputed with mean\n",
      "latitude imputed with mean\n",
      "added distance to capital\n"
     ]
    }
   ],
   "source": [
    "#Impute Latitude by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\n",
    "data_transformed = impute_column(data_transformed, \"longitude\")\n",
    "data_transformed = impute_column(data_transformed, \"latitude\")\n",
    "data_transformed = distance_capital(data_transformed)\n",
    "data_transformed.to_csv(\"./FE_steps/7 train_data_capital_ONLY.csv\", index=False)\n",
    "data_transformed = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_tsh imputed with mean for regions: ['Dodoma','Kagera','Mbeya','Tabora']\n"
     ]
    }
   ],
   "source": [
    "# Impute 0 for regions of 'Dodoma','Kagera','Mbeya','Tabora' this regions 0 ar actually missing values\n",
    "data_transformed = amount_tsh_impute_regions(data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude imputed with mean\n"
     ]
    }
   ],
   "source": [
    "#Impute Latitude by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\n",
    "data_transformed = impute_column(data_transformed, \"latitude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude imputed with mean\n"
     ]
    }
   ],
   "source": [
    "#Impute Longitude by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\n",
    "data_transformed = impute_column(data_transformed, \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population imputed with mean\n"
     ]
    }
   ],
   "source": [
    "#Impute Population by the mean of the geographical areas (increasing order \"subvillage\", \"ward\", \"lga\", \"district_code\", \"region\", \"basin\")\n",
    "data_transformed = impute_column(data_transformed, \"population\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gps_height imputed with mean\n"
     ]
    }
   ],
   "source": [
    "data_transformed = impute_column(data_transformed, \"gps_height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;\"> -------------------------- CHECKPOINT</p>\n",
    "<p style=\"color:red;\"> -------------------------- SAVE to FE folder</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.to_csv(\"./FE_steps/1 train_data_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = pd.read_csv(\"./FE_steps/1 train_data_imputed.csv\")\n",
    "data_transformed_without_impute = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Outside Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added density\n",
      "added density\n"
     ]
    }
   ],
   "source": [
    "data_transformed = density(data_transformed)\n",
    "data_transformed_without_impute = density(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pupil teacher Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = adding_PTR(data_transformed)\n",
    "data_transformed_without_impute = adding_PTR(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions\n",
    "#### Compute `age` from `construction_year` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`construction_year` converted to `age`, which is elapsed years (zeroes ignored) \n",
      "\n",
      "`construction_year` converted to `age`, which is elapsed years (zeroes ignored) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# construction_year - converts it to years elapsed (AKA age) -- (zeroes ignored)\n",
    "data_transformed = convert_construction_year(data_transformed)\n",
    "data_transformed_without_impute = convert_construction_year(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age imputed with mean\n",
      "age imputed with mean\n"
     ]
    }
   ],
   "source": [
    "# age imputed with mean of rows with same extraction_type\n",
    "data_transformed = impute_column(data_transformed,'age')\n",
    "data_transformed_without_impute = impute_column(data_transformed_without_impute,'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;\"> -------------------------- CHECKPOINT</p>\n",
    "<p style=\"color:red;\"> -------------------------- SAVE to FE folder</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.to_csv(\"./FE_steps/2 train_data_impute_age_dayse_recorded_density.csv\", index=False)\n",
    "data_transformed_without_impute.to_csv(\"./FE_steps/3 train_data_NOIMPUTE_age_dayse_recorded_density.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = pd.read_csv(\"./FE_steps/2 train_data_impute_age_dayse_recorded_density.csv\")\n",
    "data_transformed_without_impute = pd.read_csv(\"./FE_steps/3 train_data_NOIMPUTE_age_dayse_recorded_density.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD `days_since_recoreded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`date_recorded` converted to `days_since_recoreded`, which is elapsed days (zeroes ignored) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_transformed_without_impute = convert_date_recorded(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one iteration without binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`days_since_recoreded` has been binned to 8 categories:\n",
      "IntervalIndex([(1923.999, 2196.0], (2196.0, 2221.0], (2221.0, 2241.0], (2241.0, 2343.0], (2343.0, 2790.0], (2790.0, 2901.0], (2901.0, 2920.0], (2920.0, 6559.0]]\n",
      "              closed='right',\n",
      "              dtype='interval[float64]')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_transformed_without_impute = bin_feature(data_transformed_without_impute, \"days_since_recoreded\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.pyplot.show()\n",
    "ax = ((data_transformed_without_impute[data_transformed_without_impute.status_group=='functional'].days_since_recoreded.value_counts().sort_index()/len(data_transformed_without_impute.status_group))*100).plot(kind='bar',color='g', x='days_since_recoreded')\n",
    "((data_transformed_without_impute[data_transformed_without_impute.status_group=='non functional'].days_since_recoreded.value_counts().sort_index()/len(data_transformed_without_impute.status_group))*100).plot(kind='bar',color='r', x='days_since_recoreded')\n",
    "((data_transformed_without_impute[data_transformed_without_impute.status_group=='functional needs repair'].days_since_recoreded.value_counts().sort_index()/len(data_transformed_without_impute.status_group)*100)).plot(kind='bar',color='b',alpha= 0.7, ax= ax, x='days_since_recoreded')\n",
    "ax.legend([\"functional\", \"non functional\",\"functional needs repair\"])\n",
    "plt.pyplot.title('Distribution of days_since_recoreded variable ')\n",
    "plt.pyplot.xlabel('days_since_recoreded')\n",
    "plt.pyplot.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add distance to capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added distance to capital\n"
     ]
    }
   ],
   "source": [
    "data_transformed_without_impute = distance_capital(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;\"> -------------------------- CHECKPOINT</p>\n",
    "<p style=\"color:red;\"> -------------------------- SAVE to FE folder</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_without_impute.to_csv(\"FE_steps/4 train_data_NOIMPUTE_age_dayse_recorded_density_capital.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_without_impute = pd.read_csv(\"FE_steps/4 train_data_NOIMPUTE_age_dayse_recorded_density_capital.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortlisting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortlist Trainning set columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`installer` shortlisted to {'Commu', 'DANIDA', 'DWE', 'Government', 'RWE', 'other'} only \n",
      "\n",
      "`funder` shortlisted to {'Government Of Tanzania','Danida','Hesawa','Rwssp','World Bank','Kkkt','World Vision','Unicef','Tasaf','District Council', 'other'} only \n",
      "\n",
      "`lga` shortlisted to {'Njombe','Arusha Rural','Moshi Rural','Bariadi','Rungwe','Kilosa','Kasulu','Mbozi','Meru','Bagamoyo', 'other'} only \n",
      "\n",
      "`extraction_type` shortlisted to {'gravity','nira/tanira','submersible','swn 80','mono','india mark ii','afridev','ksb', 'other'} only \n",
      "\n",
      "`scheme_management` shortlisted to {'VWC','WUG','Water authority','WUA','Water Board','Parastatal','Private operator','Company', 'other'} only \n",
      "\n",
      "`region_code` shortlisted to {11,17,12,3,5,18,19,2,16,10,4,1,13,14,20, 'other'} only \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installer\n",
    "data_transformed_without_impute = shortlist_installer(data_transformed_without_impute)\n",
    "\n",
    "# funder\n",
    "data_transformed_without_impute = shortlist_funder(data_transformed_without_impute)\n",
    "\n",
    "# lga\n",
    "data_transformed_without_impute = shortlist_lga(data_transformed_without_impute)\n",
    "\n",
    "# extraction_type\n",
    "data_transformed_without_impute = shortlist_extraction_type(data_transformed_without_impute)\n",
    "\n",
    "#scheme_management\n",
    "data_transformed_without_impute = shortlist_scheme_management(data_transformed_without_impute)\n",
    "\n",
    "#region_code\n",
    "data_transformed_without_impute = shortlist_region_code(data_transformed_without_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;\"> -------------------------- CHECKPOINT</p>\n",
    "<p style=\"color:red;\"> -------------------------- SAVE to FE folder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_without_impute.to_csv(\"FE_steps/5 train_data_NOIMPUTE_age_dayse_recorded_density_capital_SHORTLISTING.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_without_impute = pd.read_csv(\"FE_steps/5 train_data_NOIMPUTE_age_dayse_recorded_density_capital_SHORTLISTING.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c2c0192e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.pyplot.figure(figsize=(20,10))\n",
    "sns.heatmap(data_transformed_without_impute.corr(),cbar=True,fmt =' .2f', annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cbfc92e1cdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_data_transformed.status_group.replace(['functional', 'non functional','functional needs repair'], [1, 2, 3], inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_transformed_without_impute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transformed_without_impute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status_group\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train_data_transformed = onehot_encode(train_data_transformed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_transformed_without_impute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./FE_Final/train_data_prepared.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: drop() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "# #train_data_transformed.status_group.replace(['functional', 'non functional','functional needs repair'], [1, 2, 3], inplace=True)\n",
    "# data_transformed_without_impute = data_transformed_without_impute.drop(columns=[\"status_group\"])\n",
    "\n",
    "# #train_data_transformed = onehot_encode(train_data_transformed)\n",
    "# data_transformed_without_impute.to_csv(\"./FE_Final/train_data_prepared.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
