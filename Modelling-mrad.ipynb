{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Packages & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit, validation_curve, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler, LabelEncoder, scale, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Datasets\n",
    "data = pd.read_csv(\"train_data_prepared.csv\")\n",
    "target = pd.read_csv(\"labels_prepared.csv\")\n",
    "target=target[[\"status_group\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.8)\n",
    "\n",
    "# rf = RFC(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# rf_score = rf.score(X_test,y_test)\n",
    "\n",
    "# print('Accuracy:', rf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class logReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7319023569023569\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"ovr\").fit(data, target)\n",
    "clf_Score = clf.score(X_test,y_test)\n",
    "print('Accuracy:', clf_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4521043771043771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB().fit(X_train.drop(['gps_height','latitude'],axis=1), y_train)\n",
    "mnb.score(X_test.drop(['gps_height','latitude'], axis=1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def grid_search(Xtrain,ytrain, k):\n",
    "     cv = KFold(k)\n",
    "    rfc= Pipeline((\n",
    "    ('one_hot', one_hot()),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "    ))\n",
    "\n",
    "    knn = Pipeline((\n",
    "    ('choose_geo', filter_d()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    svc = Pipeline((\n",
    "    ('svc', SVC()),\n",
    "    ))\n",
    "\n",
    "    lr = Pipeline((\n",
    "    ('lr',LogisticRegression(multi_class=\"ovr\")),\n",
    "    ))\n",
    "\n",
    "    rfc_parameters = {\n",
    "    'rfc__n_estimators': [10, 20, 30],\n",
    "    'rfc__criterion': ['gini', 'entropy', 'accuracy'],\n",
    "    'rfc__max_features': [5, 10, 15],\n",
    "    'rfc__max_depth': ['auto', 'log2', 'sqrt', None]\n",
    "    }\n",
    "\n",
    "    knn_parameters = {\n",
    "    'knn__n_neighbors': [3, 7, 10],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    svc_parameters = {\n",
    "    'svc__C': [0.01, 0.1, 1.0],\n",
    "    'svc__kernel': ['rbf', 'poly'],\n",
    "    'svc__gamma': [0.01, 0.1, 1.0],\n",
    "\n",
    "    }\n",
    "    lr_parameters = {\n",
    "    'mnb__alpha': [0.01, 0.1, 1.0]\n",
    "    }\n",
    "\n",
    "    pars = [parameters1, parameters2, parameters3, parameters4]\n",
    "    pips = [pipeline1, pipeline2, pipeline3, pipeline4]\n",
    "    \n",
    "    d_pred = {}\n",
    "    print \"starting Gridsearch\"\n",
    "    for i in range(len(pars)):\n",
    "        gs = GridSearchCV(pips[i], pars[i],cv =  ,  verbose=2, refit=False, n_jobs=-1)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        d_pred[pips[i]] = gs.best_estimator_\n",
    "        print \"finished Gridsearch\"\n",
    "        print gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "N_FOLDS = 10\n",
    "\n",
    "# Create the dataset\n",
    "train_set = lgb.Dataset(train_features, train_labels)\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    cv_results = lgb.cv(params, train_set, nfold = n_folds, num_boost_round = 10000, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "  \n",
    "    # Extract the best score\n",
    "    best_score = max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
