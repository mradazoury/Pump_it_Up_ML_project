{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Packages & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit, validation_curve, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler, LabelEncoder, scale, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_prep\n",
    "%run data_prep.py\n",
    "%aimport modeling\n",
    "%run modeling.py\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Datasets\n",
    "data = pd.read_csv(\"./FE_Final/train_data_prepared.csv\")\n",
    "target = pd.read_csv(\"./original_datasets/training_set_labels.csv\")\n",
    "target=target[[\"status_group\"]]\n",
    "# data  = data.drop('subvillage',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.8)\n",
    "\n",
    "# rf = RFC(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# rf_score = rf.score(X_test,y_test)\n",
    "\n",
    "# print('Accuracy:', rf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class logReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7319023569023569\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"ovr\").fit(data, target)\n",
    "clf_Score = clf.score(X_test,y_test)\n",
    "print('Accuracy:', clf_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4521043771043771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB().fit(X_train.drop(['gps_height','latitude'],axis=1), y_train)\n",
    "mnb.score(X_test.drop(['gps_height','latitude'], axis=1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.8)\n",
    "\n",
    "# rf = RFC(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# rf_score = rf.score(X_test,y_test)\n",
    "\n",
    "# print('Accuracy:', rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def grid_search(Xtrain,ytrain, k):\n",
    "     cv = KFold(k)\n",
    "    rfc= Pipeline((\n",
    "    ('one_hot', one_hot()),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "    ))\n",
    "\n",
    "    knn = Pipeline((\n",
    "    ('choose_geo', filter_d()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    svc = Pipeline((\n",
    "    ('svc', SVC()),\n",
    "    ))\n",
    "\n",
    "    lr = Pipeline((\n",
    "    ('lr',LogisticRegression(multi_class=\"ovr\")),\n",
    "    ))\n",
    "\n",
    "    rfc_parameters = {\n",
    "    'rfc__n_estimators': [10, 20, 30],\n",
    "    'rfc__criterion': ['gini', 'entropy', 'accuracy'],\n",
    "    'rfc__max_features': [5, 10, 15],\n",
    "    'rfc__max_depth': ['auto', 'log2', 'sqrt', None]\n",
    "    }\n",
    "\n",
    "    knn_parameters = {\n",
    "    'knn__n_neighbors': [3, 7, 10],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    svc_parameters = {\n",
    "    'svc__C': [0.01, 0.1, 1.0],\n",
    "    'svc__kernel': ['rbf', 'poly'],\n",
    "    'svc__gamma': [0.01, 0.1, 1.0],\n",
    "\n",
    "    }\n",
    "    lr_parameters = {\n",
    "    'mnb__alpha': [0.01, 0.1, 1.0]\n",
    "    }\n",
    "\n",
    "    pars = [parameters1, parameters2, parameters3, parameters4]\n",
    "    pips = [pipeline1, pipeline2, pipeline3, pipeline4]\n",
    "    \n",
    "    d_pred = {}\n",
    "    print \"starting Gridsearch\"\n",
    "    for i in range(len(pars)):\n",
    "        gs = GridSearchCV(pips[i], pars[i],cv =  ,  verbose=2, refit=False, n_jobs=-1)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        d_pred[pips[i]] = gs.best_estimator_\n",
    "        print \"finished Gridsearch\"\n",
    "        print gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4bc9e67420b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-aafcfee4c420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcity_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./waterways/waterway.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "city_bound = gpd.read_file(\"./waterways/waterway.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f42f6134426c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearMiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report_imbalanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "X = dataset\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=RANDOM_STATE)\n",
    "\n",
    "print('Training target statistics: {}'.format(Counter(y_train)))\n",
    "print('Testing target statistics: {}'.format(Counter(y_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=2),\n",
    "                         LogisticRegression(multi_class=\"ovr\"))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_parameters = {'n_estimators': [10, 30 ,100],\n",
    "                                             'bootstrap': [True],\n",
    "                                             'max_depth': [80, 100 ],\n",
    "                                             'max_features': ['sqrt',16 ,32],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15],\n",
    "                                            'random_state':[42]}\n",
    "rf = GridSearchCV(RFC(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=KFold(5))\n",
    "\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "\n",
    "rf.fit(X, y)\n",
    "rf.cv_results_\n",
    "feature_importances = pd.DataFrame(rf.best_estimator_.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)                                                                 ascending=False)\n",
    "\n",
    "#rf_predictions = lm.predict(X_Test_2012Q3)\n",
    "#rf.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.best_estimator_.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109259259259259"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=8,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances=feature_importances.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo5 = feature_importances['index'][feature_importances['importance']>0.003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       longitude\n",
       "1                                        latitude\n",
       "2                              quantity_group_dry\n",
       "3                                    quantity_dry\n",
       "4                                             age\n",
       "5                                      gps_height\n",
       "6                           waterpoint_type_other\n",
       "7                                      population\n",
       "8                     extraction_type_group_other\n",
       "9                                   district_code\n",
       "10                    extraction_type_class_other\n",
       "11                                quantity_enough\n",
       "12                          quantity_group_enough\n",
       "13                                     amount_tsh\n",
       "14                                    region_code\n",
       "15                          extraction_type_other\n",
       "16    waterpoint_type_communal standpipe multiple\n",
       "17             waterpoint_type_communal standpipe\n",
       "18                         payment_type_never pay\n",
       "19                              payment_never pay\n",
       "20                  funder_Government Of Tanzania\n",
       "21                                   funder_other\n",
       "22                    quantity_group_insufficient\n",
       "23                                  installer_DWE\n",
       "24                          quantity_insufficient\n",
       "25                                installer_other\n",
       "26                                  region_Iringa\n",
       "27                                 management_vwc\n",
       "28                                    permit_True\n",
       "29                                   permit_False\n",
       "30                          scheme_management_VWC\n",
       "31                            public_meeting_True\n",
       "32                      waterpoint_type_hand pump\n",
       "33                             source_type_spring\n",
       "34                                  source_spring\n",
       "35                        quantity_group_seasonal\n",
       "36                                      lga_other\n",
       "37                           payment_type_unknown\n",
       "38        days_since_recoreded_(1918.932, 2329.8]\n",
       "39                           public_meeting_False\n",
       "40                       source_class_groundwater\n",
       "41              extraction_type_group_nira/tanira\n",
       "42                           source_type_borehole\n",
       "43                                    lga_Bariadi\n",
       "44          days_since_recoreded_(2736.6, 3143.4]\n",
       "45                              quantity_seasonal\n",
       "46                         source_type_river/lake\n",
       "47                        extraction_type_gravity\n",
       "48                           installer_Government\n",
       "49                 extraction_type_class_handpump\n",
       "50                                 basin_Internal\n",
       "51                             source_machine dbh\n",
       "52                           source_class_surface\n",
       "53                  extraction_type_class_gravity\n",
       "54                                payment_unknown\n",
       "55                  extraction_type_group_gravity\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'math' has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a6598bf8dda1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'math' has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "m.len(np.array(fo5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046464646464646"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RFC(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "m.fit(X_train[np.array(fo5)],y_train)\n",
    "m.score(X_test[np.array(fo5)] , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.087157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.086078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_group_dry</th>\n",
       "      <td>0.074232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_dry</th>\n",
       "      <td>0.064778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.051071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_height</th>\n",
       "      <td>0.044672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_other</th>\n",
       "      <td>0.043605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.030686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_other</th>\n",
       "      <td>0.019994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>0.018954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class_other</th>\n",
       "      <td>0.018358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_enough</th>\n",
       "      <td>0.016290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_group_enough</th>\n",
       "      <td>0.015892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>0.015634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>0.013075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_other</th>\n",
       "      <td>0.012913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_communal standpipe multiple</th>\n",
       "      <td>0.011473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_communal standpipe</th>\n",
       "      <td>0.009833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type_never pay</th>\n",
       "      <td>0.009323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_never pay</th>\n",
       "      <td>0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder_Government Of Tanzania</th>\n",
       "      <td>0.008313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder_other</th>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_group_insufficient</th>\n",
       "      <td>0.006976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_DWE</th>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_insufficient</th>\n",
       "      <td>0.005772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_other</th>\n",
       "      <td>0.005705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Iringa</th>\n",
       "      <td>0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_vwc</th>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit_True</th>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit_False</th>\n",
       "      <td>0.005123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_other</th>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_group_other</th>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_rope pump</th>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_other</th>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_other handpump</th>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_DANIDA</th>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_india mark iii</th>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Dar es Salaam</th>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_group_colored</th>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_Bagamoyo</th>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality_coloured</th>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_group_unknown</th>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality_fluoride</th>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_unknown</th>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_group_fluoride</th>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_class_unknown</th>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_cattle trough</th>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_type_other</th>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_trust</th>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_other</th>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_other motorpump</th>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group_wind-powered</th>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class_wind-powered</th>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_other - school</th>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_unknown</th>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_recoreded_(5177.4, 5584.2]</th>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_dam</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality_fluoride abandoned</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_recoreded_(5584.2, 5991.0]</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             importance\n",
       "longitude                                      0.087157\n",
       "latitude                                       0.086078\n",
       "quantity_group_dry                             0.074232\n",
       "quantity_dry                                   0.064778\n",
       "age                                            0.051071\n",
       "gps_height                                     0.044672\n",
       "waterpoint_type_other                          0.043605\n",
       "population                                     0.030686\n",
       "extraction_type_group_other                    0.019994\n",
       "district_code                                  0.018954\n",
       "extraction_type_class_other                    0.018358\n",
       "quantity_enough                                0.016290\n",
       "quantity_group_enough                          0.015892\n",
       "amount_tsh                                     0.015634\n",
       "region_code                                    0.013075\n",
       "extraction_type_other                          0.012913\n",
       "waterpoint_type_communal standpipe multiple    0.011473\n",
       "waterpoint_type_communal standpipe             0.009833\n",
       "payment_type_never pay                         0.009323\n",
       "payment_never pay                              0.008943\n",
       "funder_Government Of Tanzania                  0.008313\n",
       "funder_other                                   0.007619\n",
       "quantity_group_insufficient                    0.006976\n",
       "installer_DWE                                  0.006794\n",
       "quantity_insufficient                          0.005772\n",
       "installer_other                                0.005705\n",
       "region_Iringa                                  0.005441\n",
       "management_vwc                                 0.005397\n",
       "permit_True                                    0.005348\n",
       "permit_False                                   0.005123\n",
       "...                                                 ...\n",
       "payment_other                                  0.000463\n",
       "management_group_other                         0.000423\n",
       "extraction_type_group_rope pump                0.000418\n",
       "management_other                               0.000405\n",
       "extraction_type_group_other handpump           0.000383\n",
       "installer_DANIDA                               0.000359\n",
       "extraction_type_group_india mark iii           0.000355\n",
       "region_Dar es Salaam                           0.000353\n",
       "quality_group_colored                          0.000335\n",
       "lga_Bagamoyo                                   0.000316\n",
       "water_quality_coloured                         0.000304\n",
       "management_group_unknown                       0.000286\n",
       "water_quality_fluoride                         0.000262\n",
       "management_unknown                             0.000250\n",
       "quality_group_fluoride                         0.000243\n",
       "source_class_unknown                           0.000213\n",
       "waterpoint_type_cattle trough                  0.000210\n",
       "source_type_other                              0.000185\n",
       "management_trust                               0.000148\n",
       "source_other                                   0.000131\n",
       "extraction_type_group_other motorpump          0.000124\n",
       "extraction_type_group_wind-powered             0.000100\n",
       "extraction_type_class_wind-powered             0.000096\n",
       "management_other - school                      0.000072\n",
       "source_unknown                                 0.000061\n",
       "days_since_recoreded_(5177.4, 5584.2]          0.000009\n",
       "waterpoint_type_dam                            0.000004\n",
       "water_quality_fluoride abandoned               0.000002\n",
       "distance                                       0.000000\n",
       "days_since_recoreded_(5584.2, 5991.0]          0.000000\n",
       "\n",
       "[199 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns)))\n",
    "\n",
    "def onehot_encode(df):\n",
    "    numericals = df.get(numerical_features(df))\n",
    "    new_df = numericals.copy()\n",
    "\n",
    "    print(\"# of features before: {}\".format(len(df.columns)))\n",
    "\n",
    "    for categorical_column in categorical_features(df):\n",
    "        new_df = pd.concat([new_df, \n",
    "                            pd.get_dummies(df[categorical_column], \n",
    "                                           prefix=categorical_column)], \n",
    "                           axis=1)\n",
    "    print(\"# of features after: {}\".format(len(new_df.columns)))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    categorical = categorical_features(df)\n",
    "    # Creating the label encoder object\n",
    "    le =  LabelEncoder()\n",
    "    \n",
    "    # Iterating over the \"object\" variables to transform the categories into numbers \n",
    "    for col in categorical:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### THIS FUNCTION RETURNS THE PREDICTION FOR TRAIN and TEST IN STACKING\n",
    "def Stacking(model,train,fold,y,test):\n",
    "    folds=fold\n",
    "    test_pred=np.empty((test.shape[0],1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    t = 0\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "     \n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        \n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "        print(model.score(x_val, y_val))\n",
    "        if model.score(x_val, y_val) > t:\n",
    "            test_pred=model.predict(test)\n",
    "    return test_pred.reshape(-1,1),train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = label_encoder(data)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8069584736251403\n",
      "0.8026936026936027\n",
      "0.8002244668911336\n",
      "0.8088664421997755\n",
      "0.8004489337822671\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "\n",
    "rfc = RFC(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "test_pred1 ,train_pred1=Stacking(model=rfc , train=X_train,fold=KFold(5),test=X_test,y=y_train)\n",
    "\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "RF_parameters = {'n_estimators': [10, 30 ,100],\n",
    "                                             'bootstrap': [True],\n",
    "                                             'max_depth': [80, 100 ],\n",
    "                                             'max_features': ['sqrt',16 ,32],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15],\n",
    "                                            'random_state':[random_seed],\n",
    "                                            'criterion':['mse']}\n",
    "# rf = GridSearchCV(RandomForestRegressor(),\n",
    "#                                  param_grid= RF_parameters,\n",
    "#                                  cv=tscv)\n",
    "\n",
    "# test_pred2 ,train_pred2=Stacking(model=rf ,train=xwe_Train,fold=tscv,test=xwe_Test,y=ywe_cnt_train)\n",
    "\n",
    "# train_pred2=pd.DataFrame(train_pred2)\n",
    "# test_pred2=pd.DataFrame(test_pred2)\n",
    "\n",
    "# param_grid = {'learning_rate': [0.01, 0.15  ,0.2], \n",
    "#           'max_depth': [8,12 , 16],\n",
    "#           'min_child_weight': [2, 3,5,10],\n",
    "#           'subsample': [0.5,  0.8],\n",
    "#           'colsample_bytree': [0.5, 0.75],\n",
    "#           'n_estimators': [18, 50 , 100],\n",
    "# }\n",
    "\n",
    "# model = xgb.XGBRegressor()\n",
    "\n",
    "# xg1 = GridSearchCV(model,\n",
    "#                     param_grid = param_grid,\n",
    "#                     cv = tscv,\n",
    "#                     n_jobs = -1,\n",
    "#                     scoring = 'r2',\n",
    "#                     verbose=True)\n",
    "\n",
    "# test_pred3 ,train_pred3=Stacking(model=xg1 ,train=xwe_Train,fold=tscv,test=xwe_Test,y=ywe_cnt_train)\n",
    "\n",
    "# train_pred3=pd.DataFrame(train_pred3)\n",
    "# test_pred3=pd.DataFrame(test_pred3)\n",
    "\n",
    "\n",
    "##### if doing time series fold check teh number of rows that where skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44520</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44521</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44522</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44523</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44524</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44525</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44526</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44527</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44528</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44529</th>\n",
       "      <td>functional needs repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44530</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44531</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44532</th>\n",
       "      <td>functional needs repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44533</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44534</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44535</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44536</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44537</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44538</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44539</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44540</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44541</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44542</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44543</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44544</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44545</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44546</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44547</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44548</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44549</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44550 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0               non functional\n",
       "1                   functional\n",
       "2                   functional\n",
       "3                   functional\n",
       "4               non functional\n",
       "5                   functional\n",
       "6                   functional\n",
       "7                   functional\n",
       "8               non functional\n",
       "9                   functional\n",
       "10                  functional\n",
       "11                  functional\n",
       "12              non functional\n",
       "13              non functional\n",
       "14                  functional\n",
       "15                  functional\n",
       "16                  functional\n",
       "17              non functional\n",
       "18                  functional\n",
       "19              non functional\n",
       "20                  functional\n",
       "21                  functional\n",
       "22              non functional\n",
       "23              non functional\n",
       "24              non functional\n",
       "25              non functional\n",
       "26                  functional\n",
       "27              non functional\n",
       "28              non functional\n",
       "29              non functional\n",
       "...                        ...\n",
       "44520               functional\n",
       "44521           non functional\n",
       "44522           non functional\n",
       "44523               functional\n",
       "44524           non functional\n",
       "44525               functional\n",
       "44526               functional\n",
       "44527               functional\n",
       "44528               functional\n",
       "44529  functional needs repair\n",
       "44530               functional\n",
       "44531           non functional\n",
       "44532  functional needs repair\n",
       "44533               functional\n",
       "44534           non functional\n",
       "44535               functional\n",
       "44536               functional\n",
       "44537               functional\n",
       "44538               functional\n",
       "44539               functional\n",
       "44540               functional\n",
       "44541               functional\n",
       "44542               functional\n",
       "44543           non functional\n",
       "44544               functional\n",
       "44545               functional\n",
       "44546               functional\n",
       "44547           non functional\n",
       "44548               functional\n",
       "44549           non functional\n",
       "\n",
       "[44550 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_pred2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-1933134a93d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_pred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxwe_Train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m795\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_pred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_pred3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxwe_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Or any model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_pred2' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train_pred1, train_pred2, train_pred3,xwe_Train.drop(np.arange(0,795)).reset_index(drop=True) ], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2,test_pred3,xwe_Test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "## Or any model \n",
    "\n",
    "param_grid = {'learning_rate': [0.01, 0.15  ,0.2], \n",
    "          'max_depth': [8,12 , 16],\n",
    "          'min_child_weight': [2, 3,5,10],\n",
    "          'subsample': [0.5,  0.8],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [18, 50 , 100],\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg1 = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = tscv,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2',\n",
    "                    verbose=True)\n",
    "\n",
    "test_pred3 ,train_pred3=Stacking(model=xg1 ,train=xwe_Train,fold=tscv,test=xwe_Test,y=ywe_cnt_train)\n",
    "\n",
    "train_pred3=pd.DataFrame(train_pred3)\n",
    "test_pred3=pd.DataFrame(test_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features before: 36\n",
      "# of features after: 199\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_parameters = {'n_neighbors':[1, 5,10,15, 30 ],'weights':['uniform'], 'algorithm':['auto'],'leaf_size':[5 ,10, 20,30],\n",
    "                  'p':[1,2,3],'metric':['minkowski']}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),verbose =True,\n",
    "                                 param_grid=knn_parameters,\n",
    "                                 cv=KFold(5,random_state = 42),return_train_score=True)\n",
    "y = target\n",
    "X =  onehot_encode(data.drop(['subvillage','ward'],axis=1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "\n",
    "knn.fit(X, y)\n",
    "knn.cv_results_\n",
    "feature_importances_knn = pd.DataFrame(rf.best_estimator_.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    " Xll = data[['longitude','latitude']]\n",
    "yll = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "knn_parameters = {'n_neighbors':[1, 5,10,15, 30 ],'weights':['uniform'], 'algorithm':['auto'],'leaf_size':[5 ,10, 20,30],\n",
    "                  'p':[1,2,3],'metric':['minkowski']}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),verbose =True,\n",
    "                                 param_grid=knn_parameters,\n",
    "                                 cv=KFold(5,random_state = 42),return_train_score=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xll, yll, random_state=42)\n",
    "knn.fit(X, y)\n",
    "knn.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    categorical = categorical_features(df)\n",
    "    # Creating the label encoder object\n",
    "    le =  LabelEncoder()\n",
    "    \n",
    "    # Iterating over the \"object\" variables to transform the categories into numbers \n",
    "    for col in categorical:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def test_score( dataset , name='test_predictions',train_id = False ):\n",
    "    K = KFold(5, random_state  = random_seed)\n",
    "    ### Label encode\n",
    "    dataset = label_encoder(dataset)\n",
    "    ### Divide test and train \n",
    "    Train= dataset.loc[(dataset['is_test'].isin([0]) )]\n",
    "    Train= Train.drop('is_test',axis=1)\n",
    "    \n",
    "    test = dataset.loc[(dataset['is_test'].isin([1]) )]\n",
    "    test = test.drop(['is_test','status_group',axis=1)\n",
    "    #### Set ID aside for test \n",
    "    ID = test['id'] \n",
    "    ### If train_id set to Trues the the ID will be kept as feature\n",
    "    if train_id = False:\n",
    "        Train = Train.set_indec('ID')\n",
    "        test = test.set_index('ID')\n",
    "    ### separate target \n",
    "    X_Train = Train.loc[:, df.columns != 'status_group']\n",
    "    y_Train = Train['status_group' ]\n",
    "    \n",
    "    #### Random forest with params from a gridsearch\n",
    "    RFC  = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=32, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "    ###Scores from cross val \n",
    "    scores = cross_val_score(RFC, X_Train, y_Train,scoring='accuracy', cv=K)\n",
    "    print('The average of the cross validation with Random Forest:{}'.format(scores.mean(), scores.std() * 2))\n",
    "    #### Refitting on the whole data \n",
    "    RFC.fit(X_Train , y_Train)\n",
    "    ### Predict on our test                 \n",
    "    predictions = RFC.predict(test)\n",
    "    ### Save the prediction file with the right format to submit \n",
    "    data = {'ID': ID, 'status_group': predictions}\n",
    "    submit = pd.DataFrame(data=data)\n",
    "    submit.to_csv('predictions/'+name+'.csv', index=False)\n",
    "    return scores , predictions \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
